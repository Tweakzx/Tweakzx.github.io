<!DOCTYPE html>
<html lang="en-us">
    <head><meta charset='utf-8'>
<meta name='viewport' content='width=device-width, initial-scale=1'><meta name='description' content='EasyScale 论文阅读笔记 Abstract 分布式同步GPU训练通常被用于深度学习。 使用固定GPU的资源约束 使得大规模的深度学习训练工作受到影响 降低了集群的利用率 纳入资'><title>【论文笔记】EasyScale论文阅读笔记</title>

<link rel='canonical' href='https://tweakzx.github.io/p/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0easyscale%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/'>

<link rel="stylesheet" href="/scss/style.min.css"><meta property='og:title' content='【论文笔记】EasyScale论文阅读笔记'>
<meta property='og:description' content='EasyScale 论文阅读笔记 Abstract 分布式同步GPU训练通常被用于深度学习。 使用固定GPU的资源约束 使得大规模的深度学习训练工作受到影响 降低了集群的利用率 纳入资'>
<meta property='og:url' content='https://tweakzx.github.io/p/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0easyscale%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/'>
<meta property='og:site_name' content='Tweakzx'>
<meta property='og:type' content='article'><meta property='article:section' content='Post' /><meta property='article:tag' content='EasyScale' /><meta property='article:tag' content='论文' /><meta property='article:published_time' content='2022-11-09T15:09:23&#43;08:00'/><meta property='article:modified_time' content='2022-11-09T15:09:23&#43;08:00'/><meta property='og:image' content='https://cdn.jsdelivr.net/gh/Tweakzx/ImageHost@main/img/202211091510408.png' />
<meta name="twitter:title" content="【论文笔记】EasyScale论文阅读笔记">
<meta name="twitter:description" content="EasyScale 论文阅读笔记 Abstract 分布式同步GPU训练通常被用于深度学习。 使用固定GPU的资源约束 使得大规模的深度学习训练工作受到影响 降低了集群的利用率 纳入资"><meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:image" content='https://cdn.jsdelivr.net/gh/Tweakzx/ImageHost@main/img/202211091510408.png' />
    </head>
    <body class="
    article-page has-toc
">
    <script>
        (function() {
            const colorSchemeKey = 'StackColorScheme';
            if(!localStorage.getItem(colorSchemeKey)){
                localStorage.setItem(colorSchemeKey, "auto");
            }
        })();
    </script><script>
    (function() {
        const colorSchemeKey = 'StackColorScheme';
        const colorSchemeItem = localStorage.getItem(colorSchemeKey);
        const supportDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches === true;

        if (colorSchemeItem == 'dark' || colorSchemeItem === 'auto' && supportDarkMode) {
            

            document.documentElement.dataset.scheme = 'dark';
        } else {
            document.documentElement.dataset.scheme = 'light';
        }
    })();
</script>
<div class="container main-container flex 
    
        extended
    
">
    
        <div id="article-toolbar">
            <a href="/" class="back-home">
                <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-chevron-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <polyline points="15 6 9 12 15 18" />
</svg>



                <span>Back</span>
            </a>
        </div>
    
<main class="main full-width">
    <article class="has-image main-article">
    <header class="article-header">
        <div class="article-image">
            <a href="/p/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0easyscale%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/">
                
                    <img src="https://cdn.jsdelivr.net/gh/Tweakzx/ImageHost@main/img/202211091510408.png" loading="lazy" alt="Featured image of post 【论文笔记】EasyScale论文阅读笔记" />
                
            </a>
        </div>
    

    <div class="article-details">
    
    <header class="article-category">
        
            <a href="/categories/%E8%AE%BA%E6%96%87/" >
                论文
            </a>
        
    </header>
    

    <h2 class="article-title">
        <a href="/p/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0easyscale%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/">【论文笔记】EasyScale论文阅读笔记</a>
    </h2>

    

    
    <footer class="article-time">
        
            <div>
                <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-calendar-time" width="56" height="56" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <path d="M11.795 21h-6.795a2 2 0 0 1 -2 -2v-12a2 2 0 0 1 2 -2h12a2 2 0 0 1 2 2v4" />
  <circle cx="18" cy="18" r="4" />
  <path d="M15 3v4" />
  <path d="M7 3v4" />
  <path d="M3 11h16" />
  <path d="M18 16.496v1.504l1 1" />
</svg>
                <time class="article-time--published">Nov 09, 2022</time>
            </div>
        

        
            <div>
                <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="12" cy="12" r="9" />
  <polyline points="12 7 12 12 15 15" />
</svg>



                <time class="article-time--reading">
                    19 minute read
                </time>
            </div>
        
    </footer>
    
</div>

    

</header>

    <section class="article-content">
    <h1 id="easyscale-论文阅读笔记">EasyScale 论文阅读笔记</h1>
<h2 id="abstract">Abstract</h2>
<ul>
<li>分布式同步GPU训练通常被用于深度学习。
<ul>
<li>使用固定GPU的资源约束
<ul>
<li>使得大规模的深度学习训练工作受到影响</li>
<li>降低了集群的利用率</li>
</ul>
</li>
<li>纳入资源弹性
<ul>
<li>往往会引入模型精度的非确定性&lt;&mdash;&ndash;缺乏隔离能力</li>
</ul>
</li>
</ul>
</li>
<li>本文介绍EasyScale，
<ul>
<li>这是一个弹性框架
<ul>
<li>可以在异构GPU上扩展分布式训练</li>
<li>同时产生确定性的深度学习模型</li>
</ul>
</li>
<li>实现了弹性的精度一致的模型训练。
<ul>
<li>EasyScale严格遵循数据并行训练流程</li>
<li>仔细追踪与精度相关的因素</li>
<li>有效利用深度学习特性进行上下文切换</li>
</ul>
</li>
<li>为了使异构GPU的计算能力达到饱和
<ul>
<li>EasyScale根据我们的作业内和作业间调度策略动态地分配工人</li>
<li>最大限度地减少GPU的空闲时间</li>
<li>并相应地提高综合作业的吞吐量。</li>
</ul>
</li>
<li>实验
<ul>
<li>部署在CompanyA的一个在线服务集群中</li>
<li>EasyScale为弹性深度学习训练作业提供动力，使其适时地利用空闲的GPU</li>
<li>在不违反SLA的情况下将集群的整体利用率提高了62.1%</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="introduction">Introduction</h2>
<ul>
<li>
<p>弹性深度学习框架很少在行业中使用</p>
<ul>
<li>根本障碍：在使用不同资源进行训练时模型准确性不一致</li>
<li>资源弹性对训练程序和模型收敛都引入了非确定性。
<ul>
<li>通过调整特定基准中的超参数（如学习率或批量大小）收敛到类似的精度不能说服用户，因为预期的计算流程已经隐性改变。</li>
<li>在改变数据集或模型结构时，对模型准确性的非确定性的担忧仍然没有得到解决，这使得深度学习从业者在拥抱资源弹性时犹豫不决</li>
</ul>
</li>
</ul>
</li>
<li>
<p>EasyScale：</p>
<ul>
<li>第一个在同构和异构 GPU 的资源弹性上实现一致模型精度的训练框架
<ul>
<li>提高了整体集群效率&lt;&mdash;-通过尽最大努力利用空闲 GPU 来进行弹性模型训练</li>
</ul>
</li>
<li>将深度学习模型训练视为科学实验，将确定性和可重复性作为第一流的目标</li>
<li>EasyScale探讨了将分布式模型训练过程与硬件资源解耦的可能性
<ul>
<li>无论分配的GPU数量和类型如何，都能产生位数一致的模型</li>
<li>这是通过一个名为EasyScaleThread的抽象来实现的
<ul>
<li>它封装了从数据加载、采样、计算到通信的所有阶段</li>
<li>并使它们与在固定的GPU中执行的完全一样</li>
</ul>
</li>
<li>EasyScale利用深度学习的特点
<ul>
<li>实现了快速的上下文切换</li>
<li>解决了训练工作者状态的潜在非确定性</li>
<li>并在资源重新配置时有效地执行追踪和检查点</li>
</ul>
</li>
<li>EasyScale引入了一个工作内策略&mdash;-&gt;以负载平衡的方式在异构GPU上安排训练工人</li>
<li>进一步优化了工作间的资源分配&mdash;-&gt;以最大限度地提高总的吞吐量。</li>
</ul>
</li>
</ul>
</li>
<li>
<p>贡献如下</p>
<ul>
<li>我们调查了现有的弹性深度学习框架和异构环境中的非确定性行为，并对散布在整个DLT软件堆栈中的位数差异进行了溯源。</li>
<li>我们介绍用于弹性分布式模型训练的EasyScale，它以确定性的方式实现了一致的准确性。EasyScale利用EasyScaleThread来保持与PyTorch DDP相同的弹性训练行为，并以可忽略不计的开销有效地进行上下文切换。</li>
<li>我们引入了新的作业内和作业间调度策略，以提高单个EasyScale作业的吞吐量和聚合集群的吞吐量，从而灵活有效地利用异构的GPU。</li>
<li>我们在生产集群中全面部署了EasyScale，将弹性训练作业与在线模型服务放在一起，在满足模型服务SLA的约束下，显著提高了集群利用率。</li>
</ul>
</li>
</ul>
<h2 id="motivation">Motivation</h2>
<h3 id="弹性训练带来的不确定性">弹性训练带来的不确定性</h3>
<ul>
<li>
<p>不一致的模型精度</p>
<ul>
<li>
<p><figure 
	>
	<a href="https://cdn.jsdelivr.net/gh/Tweakzx/ImageHost@main/img/202211100931703.png" >
		<img src="https://cdn.jsdelivr.net/gh/Tweakzx/ImageHost@main/img/202211100931703.png"
			
			
			
			loading="lazy"
			alt="image-20221110093121968">
	</a>
	
	<figcaption>image-20221110093121968</figcaption>
	
</figure></p>
</li>
<li>
<p>用弹性框架进行模型训练的多次运行，未能在使用不同数量的资源时产生一致的模型精度。</p>
<blockquote>
<ul>
<li>图2说明了ResNet18在CIFAR10上的验证精度
<ul>
<li>实验条件
<ul>
<li>这是一个用不同数量的V100 GPU训练的弹性模型</li>
<li>超参数和随机种子与默认值相同，只使用不同分配的GPU</li>
<li>TorchElastic（TE）被配置为调整学习率的线性缩放规则</li>
<li>Pollux可以自动决定相应的学习率和批次大小</li>
</ul>
</li>
<li>实验结论
<ul>
<li>与固定GPU上的分布式模型训练相比，资源弹性带来了不同的训练行为。</li>
<li>Pollux在产生模型质量方面引入了相对较小的差异，然而，这种差异仍然是不可忽视的</li>
</ul>
</li>
</ul>
</li>
<li>图3中报告了总体和每类的继续训练到100个epoch准确率
<ul>
<li>结果
<ul>
<li>总体准确率的差异仍然很明显：TorchElastic和Pollux分别为0.6%和2.8%。</li>
<li>每类准确率的差异甚至更大：达到7.4%和17.3%</li>
</ul>
</li>
<li>结论
<ul>
<li>这表明弹性训练的模型与使用固定GPU的模型相比，偏差不同。</li>
<li>其他指标仍未披露，模型质量差距的上限仍然未知</li>
</ul>
</li>
</ul>
</li>
</ul>
</blockquote>
</li>
</ul>
</li>
<li>
<p>很难理解超参带来的影响</p>
<ul>
<li>
<p><figure 
	>
	<a href="https://cdn.jsdelivr.net/gh/Tweakzx/ImageHost@main/img/202211100931919.png" >
		<img src="https://cdn.jsdelivr.net/gh/Tweakzx/ImageHost@main/img/202211100931919.png"
			
			
			
			loading="lazy"
			alt="image-20221110093137841">
	</a>
	
	<figcaption>image-20221110093137841</figcaption>
	
</figure></p>
</li>
<li>
<p>研究人员很难推理出gamma如何影响训练损失曲线</p>
<blockquote>
<ul>
<li>图4显示了ResNet50在CIFAR10上的实验
<ul>
<li>实验设置
<ul>
<li>比较对象
<ul>
<li>固定4个GPU上的DDP训练</li>
<li>1/2/4个GPU上的使用Pollux的弹性模型训练</li>
</ul>
</li>
<li>除了学习率调度器的一个超参数gamma外，其他配置都是一致的
<ul>
<li>gamma决定了本实验中20个epochs后的学习率降低比例</li>
<li>DDP实验以相同的设置运行了三次4-GPU训练，但gamma值分别为0.1、0.3和0.5</li>
<li>Pollux也运行同样的实验，1个GPU的gamma为0.1，2个GPU的gamma为0.3，而4个GPU的gamma为0.5</li>
</ul>
</li>
</ul>
</li>
<li>实验结论
<ul>
<li>使用DDP，可以清楚地推断出超参数gamma是如何影响模型训练过程的。
<ul>
<li>训练损失在前20个 epochs的三次运行中保持一致</li>
<li>之后，较小的gamma导致较小的训练损失</li>
</ul>
</li>
<li>使用Pollux，研究人员很难推理出gamma如何影响训练损失曲线。</li>
</ul>
</li>
</ul>
</li>
</ul>
</blockquote>
</li>
</ul>
</li>
<li>
<p>总结</p>
<ul>
<li><strong>DL 模型现在是算法，框架和计算资源组合的结果</strong>，这是限制 DLT 作业使用弹性资源的根本原因</li>
<li>现有的弹性 <strong>DL 框架缺乏将资源与模型超参数解耦的能力</strong>&mdash;-&gt;无法提供与弹性训练一致的模型精度</li>
<li>我们需要支持弹性训练，同时保持一致的模型精度</li>
</ul>
</li>
</ul>
<h2 id="design">Design</h2>
<h3 id="overview">Overview</h3>
<ul>
<li>
<p>弹性训练应该生成与使用固定数量的GPU进行的DDP训练相同的模型参数</p>
</li>
<li>
<p>实现弹性准确度一致的模型训练的关键挑战是找到一种实用的方法，将一个GPU有效地分享给多个worker</p>
</li>
</ul>
<h3 id="easyscalethread">EasyScaleThread</h3>
<ul>
<li>
<p>EasyScaleThread： 捕捉深度学习的训练过程并将其与硬件资源解耦</p>
<ul>
<li>每个GPU都由一个EasyScale PyTorch worker启动。</li>
<li>原始训练worker的执行被视为EST的执行，它可以动态地分配给PyTorch worker进程。</li>
<li>在一个worker中，多个EasyScaleThreads轮流占用GPU进行计算。</li>
<li>使用
<ul>
<li>通过使用白盒方法，EasyScale通过用户注释将模型训练的关键步骤挂钩，数据加载、反向传播和模型更新，因此在<strong>mini-batch边界</strong>进行精度一致的上下文切换。</li>
<li>用户定义的模型训练语义，包括模型结构、数据增量、批次大小、优化等，都照常保留。</li>
<li>至于编程，用户考虑总的逻辑训练工作者的数量来决定超参数（如全局批处理量和学习率），这与他们使用固定GPU的经验相同，但自动受益于EasyScale提供的弹性。</li>
</ul>
</li>
</ul>
</li>
<li>
<p>执行</p>
<ul>
<li>mini-batch的执行：
<ul>
<li>输入数据被分割到所有的EasyScaleThreads中</li>
<li>一个GPU上每次执行一个EST时， 其他EST被冻结</li>
<li>在所有EasyScaleThreads完成后，mini-batch就完成了</li>
</ul>
</li>
<li>当两个EasyScaleThreads切换时
<ul>
<li>EasyScaleThread的训练状态需要被保存到GPU之外，因此要确保有足够的GPU内存给下一个EasyScaleThread，这可能是昂贵的。</li>
<li>在GPU上为每个minibatch有效切换EasyScaleThreads的关键是<strong>减少上下文切换所需的状态</strong>。</li>
<li>而EasyScale选择在<strong>完成前向后向计算后</strong>切换EasyScaleThreads，最大限度地减少GPUCPU内存拷贝。</li>
</ul>
</li>
<li>我们通过以下方式最小化状态的大小：
<ul>
<li>i）定位影响最终精度的非确定性来源，最小化需要记录的必要状态</li>
<li>ii）利用DL的数据并行行为，最小化数据交换的<strong>工作集</strong>。</li>
</ul>
</li>
<li>EasyScaleThread的GPU内存中的工作集
<ul>
<li>可以分为时间张量和激活、模型参数和优化状态以及梯度，</li>
<li>处理
<ul>
<li>首先，对于时间张量和激活，它们在前向步骤中创建，在完成梯度生成后在后向步骤中销毁。
<ul>
<li>因此，它们会在小批处理结束时自动释放出来。</li>
</ul>
</li>
<li>其次，关于模型参数和优化器状态，每个数据并行工作者在训练过程中都会保留一个副本，并且在一个小批处理结束时进行更新。
<ul>
<li>因此，在EasyScale中，当切换EasyScaleThreads时，它们可以被重复使用。</li>
</ul>
</li>
<li>最后，梯度是根据EasyScaleThreads的不同数据输入计算的，因此不能重复使用。然而，梯度通常很小，并且只在minibatch结束时的分布式梯度同步中使用。
<ul>
<li>因此，在EasyScale中，我们在上下文切换时将梯度迁移到主机DRAM中，并与下一个EasyScaleThread的计算重叠。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>通过这种方式，我们交替执行EasyScaleThreads，直到所有计算完成。之后，分布式同步被触发，模型更新被进行一次以完成小批量的计算。</li>
</ul>
</li>
<li>
<p>重配置</p>
<ul>
<li>当资源重新配置被触发时，EasyScale采用<strong>按需检查点</strong>的方式来持续保持最小和必要的状态。</li>
<li>检查点包含了
<ul>
<li>所有EasyScaleThreads的上下文</li>
<li>额外的状态（包括训练进度和其他实现精度一致性的状态）</li>
<li>深度学习参数（例如，模型、优化器和学习率调度器）</li>
</ul>
</li>
<li>与EasyScaleThread上下文不同的是
<ul>
<li>额外的状态和参数只需要一个副本，因为它们在mini-batch结束时对所有EasyScaleThread都是一样的。</li>
</ul>
</li>
<li>请注意，在重新启动模型训练后，每个GPU的EasyScale运行时
<ul>
<li>会加载额外的状态和模型参数的副本</li>
<li>以及重新分布的EasyScaleThreads的相应上下文</li>
</ul>
</li>
</ul>
</li>
<li>
<p>优化</p>
<ul>
<li>
<p>为了overlap数据加载和GPU训练</p>
<ul>
<li>data loader在独立的处理器中执行（即PyTorch中的加载器工作者进程），异步加载训练样本并执行数据增强（例如，裁剪或旋转图像）以建立训练批次。</li>
<li>在EasyScale中，我们优化了所有EasyScaleThreads之间共享data loader，因为每次只有一个EasyScaleThread在GPU上进行训练。</li>
<li>尽管共享了多个EasyScaleThreads，但数据消耗率与专用GPU中的数据消耗率相似。</li>
</ul>
</li>
<li>
<p>为了实现data loader的共享</p>
<ul>
<li>
<p>EasyScale采用了一个分布式数据采样器，该采样器共同考虑了EasyScaleThreads的全局index和时分模式，在一个队列中生成数据index</p>
</li>
<li>
<p>然后，这些数据索引被数据工作者有序地处理</p>
<blockquote>
<p><figure 
	>
	<a href="https://cdn.jsdelivr.net/gh/Tweakzx/ImageHost@main/img/202211102118235.png" >
		<img src="https://cdn.jsdelivr.net/gh/Tweakzx/ImageHost@main/img/202211102118235.png"
			
			
			
			loading="lazy"
			alt="image-20221110211808582">
	</a>
	
	<figcaption>image-20221110211808582</figcaption>
	
</figure></p>
<ul>
<li>图7显示了将三个数据工作者共享给两个EasyScaleThreads的情况，其中EasyScaleThread的总数量为四个（即图6中的2-GPU训练）。</li>
<li>EST0和EST1的训练批次为：小批0的b0和b1，小批1的b4和b5。</li>
<li>在专用GPU中为EasyScaleThread i处理数据指数的数据工作者j的状态被表示为Ri-j</li>
<li>为了平衡负载，EasyScale中的数据工作者轮流从队列缓冲区中获取给定数据指数的相应状态（即Ri-j）进行预处理，完成后将状态提交回队列缓冲区中。</li>
</ul>
</blockquote>
</li>
<li>
<p>注意，由于data loader的异步执行&ndash;&gt;</p>
<ul>
<li>data loader的进程通常在训练进度之前&mdash;&gt;</li>
<li>为了跟踪和保持弹性的一致状态，引入了一个排队缓冲区来记录未被消耗的小批的必要状态&mdash;&gt;</li>
<li>worker的状态根据训练进度从队列缓冲区中去排队，然后在检查点中被视为额外状态的一部分</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="不确定性的溯源与解决">不确定性的溯源与解决</h3>
<ul>
<li>自上而下的方法来比较EasyScale和DDP， 我们发现非确定性的根本原因分散在训练管道的几乎整个软件栈中，从训练框架到通信，再到GPU内核。
<ul>
<li>首先，在训练框架层面
<ul>
<li>框架有一些状态需要在整个训练过程中保持一致，以保证确定性</li>
<li>尽管深度学习训练在DAG图中组织运算符（例如卷积、批量归一化），但一些运算符隐含地依赖一些状态，而不是其前辈的输出。例如
<ul>
<li>Dropout依赖于GPU中的随机数发生器（RNG）状态；</li>
<li>BatchNorm通过考虑工作者的等级来跟踪其运行状态；</li>
<li>数据加载器和数据增强的转化器依赖于Python、NumPy和PyTorch的随机状态，等等。</li>
</ul>
</li>
</ul>
</li>
<li>第二，在通信层面
<ul>
<li>通过全还原的梯度同步在资源弹性下是不确定的</li>
<li>在同步过程中，梯度被聚集到通信桶中，以优化通信性能。</li>
<li>梯度到桶的映射最初由DAG图的静态反转拓扑顺序决定。</li>
<li>它在第一个小批处理结束时根据收到的梯度张量的顺序进行重构。</li>
<li>然而，在弹性训练期间，工作者重新启动将重建通信渠道，这可能会影响第一个恢复的小批的梯度聚合顺序。</li>
<li>由于环形Allreduce的实现，这最终会引入非确定性。</li>
</ul>
</li>
<li>最后，在GPU内核层面
<ul>
<li>为同一运算器选择不同的内核也会导致结果的细微差别</li>
<li>导致不同内核选择的原因有两个。
<ul>
<li>首先是框架、编译器或供应商库中的一些基于剖析的优化，在小批量中应用不同的内核实现，以收集性能统计数据，找到最佳匹配。</li>
<li>另一个是内核的实现可以与硬件相关。例如，一些内核实现是基于流处理器单元的数量、硬件特定的低位组件等，因此不能应用于所有类型的GPU。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>确定性的等级与应对方案
<ul>
<li>EasyScale定义了不同级别的弹性训练的确定性，为用户提供明确的一致性保证，并设计了相应的处理方法来实现它们。</li>
<li>D0：固定DoP的确定性
<ul>
<li>&ndash;用固定的GPU资源进行多次训练应该产生相同的模型</li>
<li>实现D0需要训练框架及其所选内核的一致行为。
<ul>
<li>对于框架，我们在训练开始时<strong>固定RNG的随机种子</strong>，并在数据加载工作者状态中记录RNG的状态，在上下文中记录EasyScaleThreads的状态，以便EasyScaleThreads自动保持状态一致。</li>
<li>我们还<strong>禁用了最适合的算法选择</strong>，并选择了确定性的算法（例如，没有原子指令）。</li>
</ul>
</li>
</ul>
</li>
<li>D1：弹性确定性
<ul>
<li>&ndash;在检查点重启的情况下，用数量不断变化的同质GPU进行多次训练，应该产生相同的模型</li>
<li>在D0之外，D1需要解决通信层面的非确定性。
<ul>
<li>为此，我们为每个EasyScaleThread分配了一个固定的虚拟通信等级。</li>
<li>我们还将形成梯度桶的索引记录到检查点中。</li>
<li>重新启动后，在训练之前，首先用记录的指数重建桶。</li>
<li>后面的通信通道重建被禁止。</li>
</ul>
</li>
</ul>
</li>
<li>D2：异质性确定性
<ul>
<li>&ndash;用不同类型的GPU进行的多次训练应该产生相同的模型。</li>
<li>为了实现D2，我们开发了与硬件无关的GPU内核。具体来说，
<ul>
<li>1）我们修改内核实现（例如PyTorch中的reduce、dropout），限制SM和线程的数量；</li>
<li>2）我们通过向高层调用传递algo_id，强制选择相同的低层实现（例如cuDNN中的convolution，以及cuBLAS中的gemm、gemv）。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>如何确定确定性等级
<ul>
<li>在EasyScale中，D0和D1是<strong>默认启用</strong>的，因为我们的实现对实现它们的开销可以忽略不计</li>
<li>实现D2对于某些类型的模型（如CV模型）可能会有较高的开销，因为它们不能对某些GPU类型使用一些供应商优化的内核（如卷积）。
<ul>
<li>EasyScale可以透明地分析一个模型（通过扫描PyTorch nn.Modules），并识别它是否依赖于需要硬件特定内核优化的运算符。</li>
<li>如果不是，我们就启用D2，允许它使用异构的GPU，否则就限制它使用同构的GPU。</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="调度原则">调度原则</h3>
<ul>
<li>用户在提交EasyScale作业时
<ul>
<li>可以指定一个maxP：即要启动的最大工作者数量，这也是作业执行过程中EasyScaleThreads的数量</li>
<li>用户还可以指定一个minP（&gt;=0），表示所需的保证GPU</li>
<li>设置minP == maxP意味着作业将回到使用与DDP相同的固定DoP</li>
</ul>
</li>
<li>小结：ESTi抽象 -&gt; 确定性处理 -&gt; 调度EST
<ul>
<li><strong>EasyScaleThreads（EST）的抽象</strong>将DL训练和底层GPU资源解耦，因此与DDP兼容的训练作业可以持续地在同质GPU的弹性数量上运行。</li>
<li><strong>确定性处理</strong>实现了弹性训练下的精度一致性，即使是在异构GPU上</li>
</ul>
</li>
<li>在<strong>异构GPU上调度EST</strong>的关键挑战在于计算能力的异质性和GPU内存的异质性。
<ul>
<li>Pollux和VirtualFlow
<ul>
<li>采用为每一种GPU单独扩展批次大小的方法</li>
<li>对于EasyScale来说是完全不可接受的，因为它改变了固有的训练超参数，从而破坏了精度的一致性</li>
</ul>
</li>
<li>EST消耗固定计算能力与固定内存消耗
<ul>
<li>在EST执行过程中，每个EST消耗<strong>固定的计算能力</strong>，其中GPU的微架构特征（即SM数量和缓存大小）决定了理论能力。具有较高计算能力的GPU可以在一定时间内执行更多的EST</li>
<li>而每个EST都有<strong>固定大小的GPU内存</strong>使用峰值。此外，由于同一GPU执行器中的EST的内存是完全重复使用/共享的，执行器的内存用量可以代表EST的内存用量</li>
<li>为简洁起见，我们将固定的计算能力和内存用量分别定义为计算单元（CU）和内存单元（MU）</li>
</ul>
</li>
<li>复杂的分析规划：避免因为严重的负载不平衡而造成重大的性能浪费</li>
</ul>
</li>
</ul>
<h4 id="异构感知的est规划">异构感知的EST规划</h4>
<ul>
<li>
<p>Planning CUs</p>
<ul>
<li>分配策略
<ul>
<li>当分配的GPU是同质的，并且数量是maxP的一个因素时，在这些GPU上<strong>均匀地分配CU</strong>，因为所有CU都有相同的计算时间</li>
<li>在异构GPU的情况下，需要<strong>根据GPU的计算能力来分配</strong>CU以达到平衡，并最多消除空闲周期</li>
</ul>
</li>
<li>我们提出了一个新的指标，叫做浪费，
<ul>
<li>即由于CU的整数倍和GPU的实际连续能力不匹配而浪费的计算能力，或者说是负载不平衡。</li>
<li>浪费主要包括两个方面：
<ul>
<li>∂异构GPU之间的负载不平衡，是由于用CU的整数倍不准确地逼近连续的实际计算能力造成的；</li>
<li>∑同构GPU之间的负载不平衡，是由于没有足够的CU分配来充分利用所有的GPU，因为CU的总量被maxP所限制。</li>
</ul>
</li>
<li>因此，我们建立一个分析模型来量化浪费。
<ul>
<li>符号表示
<ul>
<li>可用的GPU数量表示为Ni，其中下标i代表GPU类型。</li>
<li>与工作负载相关的计算能力Ci被估计为每秒的小批处理数量。</li>
<li>分配给GPU类型i的CU的最大数目被表示为Ai。</li>
</ul>
</li>
<li><figure 
	>
	<a href="https://cdn.jsdelivr.net/gh/Tweakzx/ImageHost@main/img/202211122032034.png" >
		<img src="https://cdn.jsdelivr.net/gh/Tweakzx/ImageHost@main/img/202211122032034.png"
			
			
			
			loading="lazy"
			alt="image-20221112203217230">
	</a>
	
	<figcaption>image-20221112203217230</figcaption>
	
</figure></li>
<li>为了确保所有EasyScaleThreads被执行，异构GPU上的最大CU总数（CU_capacity）应该大于或等于maxP（公式1a）。</li>
<li>过载系数foverload代表所请求的异构GPU的最大过载，其中过载被定义为每个计算能力的CU（等式1b）。</li>
<li>如果一个GPU类型承担了太多的CU，它就会成为性能瓶颈，并由于Sync-SGD而拖慢其他GPU的速度。因此，浪费被表述为：∂Ci和Ai之间的差距按foverload缩放，∑超额配置的CU_capacity按foverload缩放（公式1c）。</li>
<li>为了进一步区分当前Ni、Ci和Ai下的CU分配效率，得出了归一化的浪费百分比（公式1d）。</li>
<li>还得出了估计性能（等式1e）。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p>Planning MUs</p>
<ul>
<li>
<p><strong>异构GPU之间的内存容量也存在异质性</strong></p>
<ul>
<li>将MU分配给每个GPU的单个执行器可以最大限度地减少整体内存占用，因为EasyScaleThreads引入的内存开销可以忽略不计。</li>
<li>而且它们的MU可以完全重复使用。</li>
<li>因此，所有的GPU都显示出与MU相同的峰值内存使用量，导致具有较大内存容量的GPU出现闲置内存。</li>
</ul>
</li>
<li>
<p>我们提出了一个<strong>多执行器</strong>的设计</p>
<ul>
<li>
<p>它允许在GPU上分配<strong>一个以上</strong>的执行器，这样就可以同时执行多个EST。</p>
</li>
<li>
<p>具有较大内存的GPU可以<strong>权衡</strong>执行器数量和每个执行器的EST数量</p>
<ul>
<li>同时保持   （#执行器   ×   #EST）  不变</li>
<li>例如，在分配了两个EST的情况下，有两种选择：
<ul>
<li>a）&lt;1执行器×2EST&gt;</li>
<li>b）&lt;2执行器×1EST&gt;</li>
</ul>
</li>
</ul>
</li>
<li>
<p>它拓宽了高效场景，即运行更多的执行器不会超过GPU资源（SM核、内存），即使考虑到干扰，仍然有助于提高性能。</p>
<blockquote>
<p>推荐模型（如Wide&amp;Deep）的训练通常显示出对GPU计算能力的利用不足，通常低于50%。在这种情况下，分配多个执行器可以利用剩余的计算能力，而且执行器之间不会产生不利影响，从而提高综合吞吐量。</p>
</blockquote>
</li>
</ul>
</li>
<li>
<p>我们还对（等式1）进行了调整，以对多个执行器的浪费进行建模。</p>
<ul>
<li>与工作负载相关的计算能力Ci被MCi = m × Ci × Ii所取代，表示m个执行器的整体能力，其中包括干扰Ii。</li>
<li>分配给GPU Ai的CU数量由MAi = m × Ai取代，代表m个执行器的总CU数量。</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="eeayscale-调度器">EeayScale 调度器</h4>
<ul>
<li>如图9所示，EasyScale采用了一个分层调度架构。
<ul>
<li>每个作业都包含一个<strong>作业内的调度器，名为AIMaster</strong>，它负责：
<ul>
<li>a）在同质和异质GPU之间分配EasyScaleThreads，尽量减少浪费，使资源利用率最大化；</li>
<li>b）通过估计潜在的速度提升，提出所需的资源进行扩展。</li>
</ul>
</li>
<li>此外，一个<strong>集群调度器</strong>以全局模式行事，协调作业之间的资源。</li>
</ul>
</li>
</ul>
<p><figure 
	>
	<a href="https://cdn.jsdelivr.net/gh/Tweakzx/ImageHost@main/img/202211102146741.png" >
		<img src="https://cdn.jsdelivr.net/gh/Tweakzx/ImageHost@main/img/202211102146741.png"
			
			
			
			loading="lazy"
			alt="image-20221110214614664">
	</a>
	
	<figcaption>image-20221110214614664</figcaption>
	
</figure></p>
<ul>
<li>Intra-Job scheduler
<ul>
<li>基本职责：在给定的GPU下生成EST<strong>分配配置</strong>
<ul>
<li>首先，在当前可用的GPU下，它选择估计吞吐量最高的配置，并相应分配EST。</li>
<li>其次，它试图用一个增量的GPU来扩展，从而产生新的配置，并选择top-K的配置作为提交给集群调度器的建议。</li>
</ul>
</li>
<li>配置组成与约束
<ul>
<li>由&lt;nums, executors, threads, waste, perf&gt;组成
<ul>
<li>nums, executors, threads是具有相同长度的GPU类型的数组，分别代表GPU数量、执行器数量和每个执行器的EST数量</li>
<li>waste和perf代表该配置通过分析模型估计的浪费和性能</li>
</ul>
</li>
<li>这些配置应该满足集群总资源、minP、maxP和归一化浪费的阈值（实际为30%）的约束。</li>
</ul>
</li>
<li>寻找可用配置
<ul>
<li>不同的工作负载使用不同GPU的吞吐量有差异，但在没有实际执行的情况下很难预测</li>
<li>因此，AIMaster模块使用作业的<strong>运行时执行</strong>统计数据来了解<strong>工作负载差异</strong>，并确定每个GPU类型i的工作负载相关<strong>计算能力Ci</strong>。</li>
<li>鉴于每个GPU类型i的剖析计算能力Ci，我们计算它们的整数近似值（例如，ceil(t×Ci), floor(t×Ci)），假设每个能力承担k个EST，并形成它们的组合</li>
<li>然后我们遍历这些组合，找到可用的配置。对于具有相同&lt;数、执行器、线程&gt;的配置，选择具有最小浪费的配置，其他配置则被过滤掉</li>
</ul>
</li>
<li>配置回退
<ul>
<li>对浪费的估计有时可能是不正确的，这可能会导致更差的训练性能</li>
<li>一旦在重新配置后观察到性能下降，我们就会退回到使用以前的资源并释放新分配的资源</li>
</ul>
</li>
</ul>
</li>
<li>Inter-job cluster scheduler
<ul>
<li>
<p>它通过考虑<strong>资源可用性</strong>和<strong>提案的优先级</strong>来响应AIMaster提案。</p>
<ul>
<li>为了提高集群的整体利用率和聚合作业的吞吐量</li>
<li>它采用了一种启发式算法，倾向于接受<strong>每个GPU具有较高速度</strong>的建议，如算法1所示。
<ul>
<li>作业间调度器按照报告的<strong>平均加速比</strong>对建议进行降序排序。</li>
<li>然后，它对这些建议进行循环，开始接受最高的建议。</li>
<li>如果多个建议引入了相同的平均GPU加速，我们的调度器会<strong>优先考虑拥有更多GPU</strong>的建议。</li>
</ul>
</li>
</ul>
<p><figure 
	>
	<a href="https://cdn.jsdelivr.net/gh/Tweakzx/ImageHost@main/img/202211122105011.png" >
		<img src="https://cdn.jsdelivr.net/gh/Tweakzx/ImageHost@main/img/202211122105011.png"
			
			
			
			loading="lazy"
			alt="image-20221112210504940">
	</a>
	
	<figcaption>image-20221112210504940</figcaption>
	
</figure></p>
</li>
<li>
<p>集群调度器允许弹性作业最好地<strong>利用空闲资源</strong></p>
<ul>
<li>这些资源通常属于其他人，但暂时是闲置的。</li>
<li>然而，如果这些GPU需要返回，可能会触发抢占。
<ul>
<li>在这种情况下，集群调度器将尝试把与抢占的GPU相同的GPU分配给弹性作业。</li>
<li>当分配超时时，EasyScale作业会回落到利用它目前拥有的可用GPU。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="implementation">Implementation</h2>
<ul>
<li>
<p>DLT 作业在具有 EasyScale 实现的 Docker 容器中运行。</p>
<ul>
<li>在 Kubernetes 上实现了一个原型自定义集群调度器以进行评估。</li>
<li>EasyScale 在我们内部的 GPU 集群调度器中得到了充分的实现，它是 Kubernetes 调度器的一个优化版本，可以为日常的 GPU 生产任务提供服务。</li>
</ul>
</li>
<li>
<p>DL 框架中 EasyScale 的实现与 PyTorch 1.8 LTS 兼容。</p>
<ul>
<li>它需要大约1,200行 Python 代码和2,000行 PyTorch 中的 C + + 修改代码，以及一个基于 PyTorch 实现的插件库。</li>
<li>PyTorch 框架的 C + + 实现包括一个支持弹性的分布式数据并行通信库 ElasticDDP，它可以支持多个 EasyScaleThread 之间的通信，以全面减少梯度，并在触发资源弹性时在重新启动任务时始终如一地构建通信桶。</li>
<li>执行流控制和上下文切换作为 PyTorch 的附加组件在 Python 模块中实现。</li>
</ul>
</li>
<li>
<p>实现了 AIMaster</p>
<ul>
<li>为了决定负载平衡分配并控制作业以使用更多的 GPU 进行扩展</li>
<li>三个组成部分。
<ul>
<li>首先，我们通过一个 rpc 库收集 EasyScale 运行时报告的性能分析。</li>
<li>其次，我们提出资源建议并监视状态，从而通过 Kubernetes Python 告密者了解资源分配超时。</li>
<li>第三，实现策略控制器来计算增量资源请求并将其提交给集群调度器。为了支持资源弹性时的持续工作培训，我们采用按需检查点记录用户定义的模型，时代和小批量状态以及基本上下文切换状态</li>
</ul>
</li>
</ul>
</li>
<li>
<p>一个半自动剖析工具来执行张量之间的按位比较</p>
<ul>
<li>从而找到运算符不一致的结果，识别资源弹性中不确定性的来源。</li>
</ul>
</li>
</ul>

</section>


    <footer class="article-footer">
    
    <section class="article-tags">
        
            <a href="/tags/easyscale/">EasyScale</a>
        
            <a href="/tags/%E8%AE%BA%E6%96%87/">论文</a>
        
    </section>


    
    <section class="article-copyright">
        <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-copyright" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="12" cy="12" r="9" />
  <path d="M14.5 9a3.5 4 0 1 0 0 6" />
</svg>



        <span>Licensed under CC BY-NC-SA 4.0</span>
    </section>
    </footer>


    
        <link 
                rel="stylesheet" 
                href="https://cdn.jsdelivr.net/npm/katex@0.13.13/dist/katex.min.css"integrity="sha384-RZU/ijkSsFbcmivfdRBQDtwuwVqK7GMOw6IMvKyeWL2K5UAlyp6WonmB8m7Jd0Hn"crossorigin="anonymous"
            ><script 
                src="https://cdn.jsdelivr.net/npm/katex@0.13.13/dist/katex.min.js"integrity="sha384-pK1WpvzWVBQiP0/GjnvRxV4mOb0oxFuyRxJlk6vVw146n3egcN5C925NCP7a7BY8"crossorigin="anonymous"
                defer="true"
                >
            </script><script 
                src="https://cdn.jsdelivr.net/npm/katex@0.13.13/dist/contrib/auto-render.min.js"integrity="sha384-vZTG03m&#43;2yp6N6BNi5iM4rW4oIwk5DfcNdFfxkk9ZWpDriOkXX8voJBFrAO7MpVl"crossorigin="anonymous"
                defer="true"
                >
            </script><script>
    window.addEventListener("DOMContentLoaded", () => {
        renderMathInElement(document.querySelector(`.article-content`), {
            delimiters: [
                { left: "$$", right: "$$", display: true },
                { left: "$", right: "$", display: false },
                { left: "\\(", right: "\\)", display: false },
                { left: "\\[", right: "\\]", display: true }
            ]
        });})
</script>
    
</article>

    <aside class="related-contents--wrapper">
    
    
        <h2 class="section-title">Related contents</h2>
        <div class="related-contents">
            <div class="flex article-list--tile">
                
                    
<article class="has-image">
    <a href="/p/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0harmony%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/">
        
        
            <div class="article-image">
                
                    <img src="https://cdn.jsdelivr.net/gh/Tweakzx/ImageHost@main/img/202301041018146.png" loading="lazy" data-key="" data-hash="https://cdn.jsdelivr.net/gh/Tweakzx/ImageHost@main/img/202301041018146.png"/>
                
            </div>
        

        <div class="article-details">
            <h2 class="article-title">【论文笔记】Harmony论文阅读笔记</h2>
        </div>
    </a>
</article>
                
                    
<article class="has-image">
    <a href="/p/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0gandiva%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/">
        
        
            <div class="article-image">
                
                    <img src="https://cdn.jsdelivr.net/gh/Tweakzx/ImageHost@main/img/202211081933118.png" loading="lazy" data-key="" data-hash="https://cdn.jsdelivr.net/gh/Tweakzx/ImageHost@main/img/202211081933118.png"/>
                
            </div>
        

        <div class="article-details">
            <h2 class="article-title">【论文笔记】Gandiva论文阅读笔记</h2>
        </div>
    </a>
</article>
                
                    
<article class="has-image">
    <a href="/p/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0gaiagpu%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/">
        
        
            <div class="article-image">
                
                    <img src="https://cdn.jsdelivr.net/gh/Tweakzx/ImageHost@main/img/20220826142857.png" loading="lazy" data-key="" data-hash="https://cdn.jsdelivr.net/gh/Tweakzx/ImageHost@main/img/20220826142857.png"/>
                
            </div>
        

        <div class="article-details">
            <h2 class="article-title">【论文笔记】GaiaGPU论文阅读笔记</h2>
        </div>
    </a>
</article>
                
                    
<article class="has-image">
    <a href="/p/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0polardb-serverless%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E6%8A%A5%E5%91%8A/">
        
        
            <div class="article-image">
                
                    <img src="https://2021.sigmod.org/images/2021sigmod-logo1.jpg" loading="lazy" data-key="" data-hash="https://2021.sigmod.org/images/2021sigmod-logo1.jpg"/>
                
            </div>
        

        <div class="article-details">
            <h2 class="article-title">【论文笔记】PolarDB-Serverless论文阅读报告</h2>
        </div>
    </a>
</article>
                
                    
<article class="has-image">
    <a href="/p/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0dnn%E8%AE%AD%E7%BB%83%E8%B4%9F%E8%BD%BD%E5%88%86%E6%9E%90/">
        
        
            <div class="article-image">
                
                    <img src="https://cdn.jsdelivr.net/gh/Tweakzx/ImageHost@main/img/202302131401477.png" loading="lazy" data-key="" data-hash="https://cdn.jsdelivr.net/gh/Tweakzx/ImageHost@main/img/202302131401477.png"/>
                
            </div>
        

        <div class="article-details">
            <h2 class="article-title">【论文笔记】DNN训练负载分析</h2>
        </div>
    </a>
</article>
                
            </div>
        </div>
    
</aside>

     
    
        
    <script
    src="https://giscus.app/client.js"
    data-repo="Tweakzx/Tweakzx.github.io"
    data-repo-id="MDEwOlJlcG9zaXRvcnkzMjY5MTY1NTE="
    data-category="Announcements"
    data-category-id="DIC_kwDOE3xZx84CTfL-"
    data-mapping="title"
    data-reactions-enabled="1"
    data-emit-metadata="0"
    data-theme="light_tritanopia"
    crossorigin="anonymous"
    async
></script>
<script>
    function setGiscusTheme(theme) {
        let giscus = document.querySelector('iframe.giscus-frame');
        if (giscus) {
            giscus.contentWindow.postMessage(
                { 
                    giscus: {
                        setConfig: { 
                            theme: theme 
                        }
                    }
                },
                "https://giscus.app"
            );
        };
    };

    (function(){
        addEventListener('message', (e) => {
            if (event.origin !== 'https://giscus.app') return;
            handler()
        });
        window.addEventListener('onColorSchemeChange', handler);

        function handler() {
            if (document.documentElement.dataset.scheme === "light") {
                setGiscusTheme('light_tritanopia');
            } else {
                setGiscusTheme('dark_tritanopia');
            };
        };
    }());
</script>

    

    <footer class="site-footer">
    <section class="copyright">
        &copy; 
        
            2020 - 
        
        2023 Tweakzx
    </section>
    
    <section class="powerby">
        Built with <a href="https://gohugo.io/" target="_blank" rel="noopener">Hugo</a> <br />
        Theme <b><a href="https://github.com/CaiJimmy/hugo-theme-stack" target="_blank" rel="noopener" data-version="3.5.0">Stack</a></b> designed by <a href="https://jimmycai.com" target="_blank" rel="noopener">Jimmy</a>
    </section>
</footer>


    
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    
    <div class="pswp__bg"></div>

    
    <div class="pswp__scroll-wrap">

        
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                
                
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                        <div class="pswp__preloader__cut">
                            <div class="pswp__preloader__donut"></div>
                        </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div>
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div><script 
                src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js"integrity="sha256-ePwmChbbvXbsO02lbM3HoHbSHTHFAeChekF1xKJdleo="crossorigin="anonymous"
                defer="true"
                >
            </script><script 
                src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js"integrity="sha256-UKkzOn/w1mBxRmLLGrSeyB4e1xbrp4xylgAWb3M42pU="crossorigin="anonymous"
                defer="true"
                >
            </script><link 
                rel="stylesheet" 
                href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.css"integrity="sha256-c0uckgykQ9v5k&#43;IqViZOZKc47Jn7KQil4/MP3ySA3F8="crossorigin="anonymous"
            ><link 
                rel="stylesheet" 
                href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.css"integrity="sha256-SBLU4vv6CA6lHsZ1XyTdhyjJxCjPif/TRkjnsyGAGnE="crossorigin="anonymous"
            >

            </main>
    
        <aside class="sidebar right-sidebar sticky">
            <section class="widget archives">
                <div class="widget-icon">
                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-hash" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <line x1="5" y1="9" x2="19" y2="9" />
  <line x1="5" y1="15" x2="19" y2="15" />
  <line x1="11" y1="4" x2="7" y2="20" />
  <line x1="17" y1="4" x2="13" y2="20" />
</svg>



                </div>
                <h2 class="widget-title section-title">Table of contents</h2>
                
                <div class="widget--toc">
                    <nav id="TableOfContents">
  <ol>
    <li><a href="#abstract">Abstract</a></li>
    <li><a href="#introduction">Introduction</a></li>
    <li><a href="#motivation">Motivation</a>
      <ol>
        <li><a href="#弹性训练带来的不确定性">弹性训练带来的不确定性</a></li>
      </ol>
    </li>
    <li><a href="#design">Design</a>
      <ol>
        <li><a href="#overview">Overview</a></li>
        <li><a href="#easyscalethread">EasyScaleThread</a></li>
        <li><a href="#不确定性的溯源与解决">不确定性的溯源与解决</a></li>
        <li><a href="#调度原则">调度原则</a>
          <ol>
            <li><a href="#异构感知的est规划">异构感知的EST规划</a></li>
            <li><a href="#eeayscale-调度器">EeayScale 调度器</a></li>
          </ol>
        </li>
      </ol>
    </li>
    <li><a href="#implementation">Implementation</a></li>
  </ol>
</nav>
                </div>
            </section>
        </aside>
    

        </div>
        <script 
                src="https://cdn.jsdelivr.net/npm/node-vibrant@3.1.5/dist/vibrant.min.js"integrity="sha256-5NovOZc4iwiAWTYIFiIM7DxKUXKWvpVEuMEPLzcm5/g="crossorigin="anonymous"
                defer="false"
                >
            </script><script type="text/javascript" src="/ts/main.js" defer></script>
<script>
    (function () {
        const customFont = document.createElement('link');
        customFont.href = "https://fonts.googleapis.com/css2?family=Lato:wght@300;400;700&display=swap";

        customFont.type = "text/css";
        customFont.rel = "stylesheet";

        document.head.appendChild(customFont);
    }());
</script>

    </body>
</html>
