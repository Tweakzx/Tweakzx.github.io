---
title: "【论文笔记】Pollux论文阅读笔记"
description: 
date: 2022-11-15T16:40:57+08:00
image: https://cdn.jsdelivr.net/gh/Tweakzx/ImageHost@main/img/202211151754733.png
math: 
license: 
hidden: false
comments: true
draft: true
categories: 论文
tags: 
    - 论文
    - Pollux
    - GPU
---

# Pollux论文阅读笔记

## Abstract

- Pollux通过在每个作业层面和整个集群层面自适应地共同优化相互依赖的因素，改善深度学习（DL）集群的调度性能。
  - 在训练过程中监测每个作业的状态，Pollux建模了他们的有效吞吐量随着添加或删除资源而发生的变化
  - Pollux动态地重新分配资源，以提高整个集群的好产量，同时尊重公平性，不断优化每个DL作业，以更好地利用这些资源。
- 在真实的DL作业和跟踪驱动的模拟实验
  - Pollux相对于最先进的DL调度器将平均作业完成时间减少了37-50%
  - Pollux促进了竞争资源的DL作业之间的公平性

## Introduction

- 已有的工作
  - 现有的调度器需要用户手动配置他们的工作，如果操作不当，会大大降低训练性能和资源效率。例如，分配太多的GPU可能导致排队时间过长和资源使用效率低下，而分配太少的GPU可能导致运行时间过长和资源未被使用。这样的决定在共享集群环境中尤其难以做出，因为最佳选择是动态的，取决于作业运行时的集群负载。
  - 即使最近的弹性调度器可以为每个作业自动选择适当的资源量，他们这样做也是盲目的，因为相互依赖的训练相关配置同样重要。例如，DL任务的批处理量和学习率会影响训练其模型所需的计算量。它们的最佳选择在不同的DL任务和模型架构之间是不同的，而且它们对作业的资源分配有很强的依赖性。
  - 如果没有关于集群硬件性能和DL模型结构的专家知识，很难适当地配置资源量、批量大小和学习率。由于它们的最佳值之间的相互依赖性，它们应该相互联合配置。由于共享集群的动态性质，它们的最佳值可能会随着时间的推移而改变。这就形成了一个复杂的考虑网络，用户必须为有效执行和资源利用而配置他们的工作。

- 集群调度器如何帮助自动配置用户提交的DL作业？从根本上说，一个正确配置的DL作业要在两个经常对立的愿望之间取得平衡：
  - （1）系统吞吐量，每个壁钟时间内处理的训练实例的数量，
  - （2）统计效率，每个训练实例处理的进展量。

![image-20221116124438821](https://cdn.jsdelivr.net/gh/Tweakzx/ImageHost@main/img/202211161244925.png)

如图1a所示，系统吞吐量可以通过增加批处理量来提高。较大的批处理量可以使更多的计算资源（如更多的GPU）得到更高的利用率。但是，即使有一个经过优化调整的学习率，增加批处理规模往往会导致统计效率下降[46, 57]。对于每一个不同的GPU分配，都可能有不同的批处理规模，以最佳方式平衡增加系统的吞吐量与降低统计效率。此外，统计效率随批次大小下降的速度取决于当前的训练进度。在训练的后期阶段，一个工作有可能容忍10倍或更大的批处理量，而不会降低统计效率，而在训练的早期[46]。。

在这些见解的指导下，本文提出了Pollux，一个混合的资源调度器，它可以共同适应地分配资源，并调整共享集群中所有DL作业的批量大小和学习率。Pollux通过联合管理几个系统级和训练相关的参数来实现这一点，包括GPU的数量、工作者的共处位置、每个GPU的批处理量、梯度积累和学习率的扩展。、

- 我们提出了DL工作的goodput的表述，它是对训练性能的整体衡量，同时考虑了系统吞吐量和统计效率。
- 我们表明，可以通过观察DL作业的吞吐量和训练期间的统计行为来学习DL作业的良好吞吐量模型，并用于预测不同资源分配和批量大小下的性能。
- 我们设计并实现了一个调度架构，使用这样的模型来为每个待定和运行的DL作业配置资源分配和训练参数的正确组合。这包括为每个DL作业在本地调整系统级和训练相关的参数，并在全球范围内优化集群的资源分配。本地和全局组件积极沟通并相互合作，基于良好产出最大化的共同目标运作。
- 我们在一个集群测试平台上使用来自微软集群跟踪的工作负载来评估Pollux。与最近的DL调度器Tiresias[22]和Optimus[52]相比，Pollux减少了平均作业完成时间达73%。即使所有的作业都事先进行了手动调整，Pollux也能将平均作业完成时间减少37%-50%。同时，Pollux将完成时间的公平性[43]提高了1.5倍-5.4倍。
- 我们表明，在云环境中，使用基于Pollux的goodput驱动的自动扩展，有可能将大型模型的训练成本降低25%。