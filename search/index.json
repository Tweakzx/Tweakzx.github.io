[{"content":"《The Google File System》 论文阅读笔记 Abstract Introduction Design Overview Assumptions Interface Architecture Single Master Chunk Size Metadata In-Memory Data Structure Chunk Locations Operation Log Cosistency Model Guarantees By GFS Implications for Applications System Interactions Master Operation FAULT TOLERANCE AND DIAGNOSIS MEASUREMENTS EXPERIENCES RELATED WORK CONCLUSIONS ","date":"2022-09-20T16:25:26+08:00","image":"https://cdn.jsdelivr.net/gh/Tweakzx/ImageHost@main/img/20220920170446.png","permalink":"https://tweakzx.github.io/p/gfs%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/","title":"GFS论文阅读笔记"},{"content":"《AntMan: Dynamic Scaling on GPU Clusters for Deep Learning》论文阅读笔记 Abstract 如何在大规模GPU集群上有效调度深度学习工作， 对于工作性能，系统吞吐量和硬件利用率至关重要。\n随着深度学习的工作量变得更加复杂，它变得越来越具有挑战性。\n本文将介绍Antman， 这是一种深入学习的基础设施，该基础架构共同设计了集群调度程序，并已在阿里巴巴部署在生产中，以管理数以万计的每日深度学习工作。\n Antman适应深度学习训练的波动资源需求。因此，它利用备用GPU资源在共享GPU上共同执行多个作业。 Antman利用深度学习训练的独特特征，在深度学习框架内为显存和计算资源引入动态缩放机制。这允许job之间的细粒度协调并防止工作干扰。 评估表明，Antman在我们的多租户集群中不损害公平性的情况下，整体将显存利用率提高了42％，计算资源利用率提高了34％，为有效利用大规模的GPU提出了新方法。  Introduction  在共享多租户的DL集群， 许多工作排队等待资源的时候会导致GPU利用率低下，有两个原因  大多数的训练任务在执行过程中不能完全利用GPU资源  训练一个DL模型通常需要多种计算的混合 当使用分布式的训练的时候，90%的时间会被浪费到网络通信上   基于资源预留的集群调度方案导致显著的GPU空闲，DL工作中总有部分资源没有投入使用  例如，随机梯度下降是同步的，需要获取所有的资源以进行gang-scheduling， 在得到所有资源之前，已得到的部分资源就会陷入空闲     在共享GPU上进行packing job  可以提高GPU的利用率，可以使得同样的集群整体上胜任更多的job。 但是这个策略在生产集群上很少使用， 原因  尽管提升GPU的利用率是有利的，但也要保证resource-guarantee jobs（RGJ，资源保证性job）的性能。同一个GPU上同时执行多个job会导致干扰\u0026ndash;\u0026gt;RGJ性能出现显著下降 job packing策略可以给并发job引入内存竞争。job需要的资源陡然增加的话，有可能导致训练任务failure。   因此，job资源的独占分配在显存的GPU集群生产环境中比较典型   我们提出AntMan  简述  一个DL系统提高GPU集群的利用率 同时保证公平性与RGJ的性能 通过合作性的资源扩缩来减少job干扰   DL系统中引入了新的分配机制在job训练过程中来动态地精确分配所需资源（显存和计算单元） 使用超卖机制使得任何空闲的GPU资源（显存和计算单元）都能被利用 重新设计了集群调度器和DL框架来适应生产job的波动的资源特点  通过  框架信息感知调度 透明显存扩展 快速可持续的任务间协调   使用这个结构，Antman为DL任务的同时执行的policy design 开辟了空间   AntMan采用了简单且有效的策略来最大化集群吞吐  为RGJ提供资源保证的同时 分配一些偶然性的任务来尽力而为的利用GPU资源（低优先级且不保证资源）     本文主要贡献如下  对生产环境的DL集群进行调研，发现低利用率来自于三个方面：硬件，集群调度，job行为 在DL框架中为显存和计算单元管理引入了两种动态放缩机制，来解决GPU共享问题。新机制利用DL的工作特征来动态调整DL job的资源使用情况，在作业执行期间。 通过共同设计集群调度器和DL框架以利用动态缩放机制，我们为GPU共享引入了一种新的工业方法。这在多租户集群中维护工作服务级协议（SLA），同时通过机会调度来改善集群利用率。 在超过5000个GPU上进行了实验    Motivation deep learning Training  深度学习训练通常包括数百万次迭代，每个迭代过程都称为mini-batch。  通常，训练mini-batch可以分为三个阶段。  首先，计算样品和模型权重以产生一组得分，称为forward pass 其次，使用目标函数在产生的分数和所需的分数之间计算loss error。然后，损失通过模型向后扩散，以计算梯度，称为backward pass。 最后，通过由优化器定义的学习率来缩放梯度，以更新模型参数。   正向通行的计算输出通常包括许多数据输出，每个数据输出称为张量。这些张量应暂时保存在内存中，并被向后通过以计算梯度。通常，为了监视培训中的模型质量，定期触发评估.   为了使用大量数据培训模型，DL通常在多个GPU中采用数据并行性，其中每个GPU负责并行处理数据子集，同时在模型更新之前执行每个迷你批次梯度同步。 在大型公司中，多租户集群通常用于改善硬件利用率，用户有时可以超额订阅GPU资源配额，尤其是当GPU要求爆发时。  Characterizing Production DL Cluster 我们从三个角度研究生产集群中的资源使用率：硬件，集群调度和job行为。\n  在使用中的GPU的低利用率\n \rimage-20220831200958715\r 内存容量。如图所示，只有20％的GPU正在运行消耗一半以上GPU存储器的应用程序。 关于计算单元的使用，只有10％的GPU获得了高于80％的GPU利用率。 该统计数据表明，GPU内存和计算单元均未得到充分利用，因此浪费了昂贵的硬件资源。    对gang-schedule的空闲等待\n Gang scheduling是在并发系统中将多个相关联的进程调度到不同处理器上同时运行的策略，其最主要的原则是保证所有相关联的进程能够同时启动，防止部分进程的异常，导致整个关联进程组的阻塞。例如，您提交一个批量Job，这个批量Job包含多个任务，要么这多个任务全部调度成功，要么一个都调度不成功。这种All-or-Nothing调度场景，就被称作Gang scheduling。\n  \rimage-20220831201015900\r 多GPU训练工作需要Gang scheduling，这意味着除非同时提供所有必需的GPU，否则job将不会开始训练 由于GPU资源往往不能同时全部获得， 所以会出现idle waiting。 一个job需要的GPU越多， 它的平均闲置时间就越长 **资源到达的不可预测导致了预留资源的idle waiting。**一个幼稚的解决方案是在GPU idle waiting的时候执行别的job。但是这会导致资源需求大job的饥饿，影响分配公平性。另外一旦资源需要被满足导致的GPU需求激增或许导致GPU之间的资源冲突，导致工作fail    动态资源需求\n \rimage-20220831201047910\r 在一个DL job生命周期中， GPU资源往往未被充分利用。 图3：在Criteo数据集上运行DEEPFM [20]时的前10分钟。一开始，数据集上的预处理仅需要CPU。但是，GPU的SM利用率和内存使用量在275秒时启动。 图4：训练可以包含几个阶段，不同阶段的SM和Memory的使用率都是不一样的 资源需求的动态变化与固定的资源分配和漫长的训练时间相矛盾。资源需要满足job的峰值需要，导致这个昂贵的硬件被低效利用。显存的DL框架的memory caching设计隐藏了显存使用随时间的变化，一定程度上阻止了GPU的潜在共享。    Opportunities in DL Uniqueness   超卖有机会提高集群的吞吐\n 不可预测的job内和job间的需求激增为安全的资源共享引入了挑战  因为资源竞争， jobs可能会把显存用光 在多租户集群中，当jobs在共享环境执行时，为持有定额资源的job提供性能隔离是十分重要的   AntMan利用DL training的特性来利用这个机会    我们在生产环境集群的10k个task中取样发现\n \rimage-20220905143619325\r 只有一小部分用来存储模型， 且90%的模型大小不超过500M 大部分显存在同一个mini-batch中被分配和释放 除此之外，一个mini-batch的消耗时间很短， 80%的任务在600ms之内消耗一个mini-batch    我们通过多种方式利用这种独特的特征来安排共享GPU上的作业。\n 首先，根据通常的模型大小，大部分显存在共同执行的作业中可以拿来调度 其次，mini-batch的周期通常很短，可以在每个mini-batch边界处进行细粒度的GPU内存和计算资源的调度。这可以进一步允许job间的快速资源协调。 第三，mini-batch通常进行相似的计算，这可以被利用去描述job性能，因此进度率可以被创建作为性能矩阵来量化干扰。    Design AntMan深入共同设计集群调度程序和DL框架， 本部分将介绍三部分：DL 框架的修改，调度器与调度原则\nDynamic Scaling in DL Frameworks  低使用效率的GPU集群有着执行更多任务的潜力，但需要解决一下挑战  使用最下需求执行job的同时防止GPU内存使用的爆发导致的失效 适应计算单元的使用波动的同时限制潜在的干扰   DL框架是专注于GPU执行， 缺乏job合作的能力。这激发了动态缩放机制的设计，机制包含内存和计算两部分  Memory Management AntMan以tensor为单位，在GPU和CPU的内存间进行动态内存管理。类似于操作系统的虚拟内存，AntMan以tensor为单位进行了显存虚拟化，通过这种方式，DL框架可以提供超出上限的显存。\n  显存分配\n \rimage-20220905151151692\r 在张量被销毁后，GPU内存被缓存在DL框架内的一个全局内存分配器中，普遍情况下，一些张量只在DL训练的某些阶段使用（如数据预处理、评估），不再需要了。然而，这部分缓存的GPU内存不会被释放（图6c）。DL框架中的这种缓存内存设计优化了单个作业的性能，但代价是失去了共享潜力。 AntMan转向了扩展GPU内存上限的方法。它主动检测使用中的内存，以缩小缓存的内存，从而自省地将GPU内存的使用调整合适。这是通过监测应用性能和处理小批量时的内存需求来实现的（图6d）。AntMan使用其最大的努力在GPU设备上分配张量，然而，如果GPU内存仍然缺乏，张量可以在GPU之外用主机内存分配（图6e）。当GPU内存的上限增加时，Tensors可以自动分配回GPU（图6f）。    显存上限动态调整\n  \rimage-20220905151235705\r\n  图7a说明了内存扩展如何解决突发需求。在T0，正在运行的DL训练作业的内存需求增加，由于GPU内存的有限上限，一些张量不能放在GPU内存中，而是使用主机内存创建。AntMan检测到主机内存的使用情况，在T1，它根据主机内存的使用情况提高该作业的GPU内存的上限，虽然在这一个小批次中，这个运行作业的性能可能会减慢，因为张量被放置在主机内存中，但是后续的tensor都会申请到显存上。考虑到一个典型的DL训练往往需要数百万个小批次，这种性能开销是可以忽略不计的。\n    运行时显存细粒度调整\n 此外，AntMan在运行时提供细粒度的GPU内存调度。如图7b所示，一个训练作业可能会收缩以确保其他作业的内存资源，并在其他作业完成后再增长。它说明了一个DL作业在T0时缩减，在T1时增加，代价是在主机内存上分配了一些张量。因此，在同一共享GPU中运行的作业在T0和T1之间对剩余GPU内存的使用是有保障的。    Computation Management  动态计算单元管理，用于控制DL训练作业的GPU利用率。   类似cgroup，可以在运行时动态地隔离DL特定进程的GPU计算资源访问。\n  当多个DL作业在同一个GPU上启动时，干扰主要是由潜在的GPU内核排队延迟和PCIe总线争用引起的，这会导致所有作业的性能一致下降，如果packing job是在相同的模型和配置上运行的话。\n  **如果不同的作业被打包在一起，作业会以不同的方式变慢。**这是因为作业在获取GPU计算单元方面有不同的能力。因此，作业性能在GPU共享中几乎无法保证或预测，导致多租户集群的GPU共享部署困难。\n  AntMan中，GPU运算器的执行是由一个新引入的模块负责的，称为GpuOpManager。\n 当GPU运算器准备执行时，它被添加到GpuOpManager，而不是直接启动。 GpuOpManager的主要思想是通过延迟执行GPU运算符来控制启动频率。GpuOpManager通过这种方式来限制DL训练作业的GPU利用率。GpuOpManager不断对GPU运算器的执行时间进行分析，并在启动GPU运算器之前简单地分配空闲的时间段。 请注意，GpuOpManager只是延迟了GPU内核的执行。因此，运算符（包括GPU运算符和CPU运算符）之间的潜在依赖关系被保留下来，这意味着如果可能的话，CPU运算符可以继续。    \rimage-20220905151222951\r\n 图8说明了在同一GPU上执行的两个作业的GPU计算单元干扰的例子。图8a说明了Job-A是如何以细粒度的方式在GPU上执行的。简而言之，GPU内核将被按顺序放置，并由GPU计算单元逐一处理。请注意，在图8中，Job-A可能无法使GPU完全饱和，导致GPU周期闲置，GPU利用率低，有可能被其他作业使用。\n因此，作业-B被安排在这个GPU上（图8b）。Job-B的GPU操作者启动在GPU中执行的内核（绿色块），这可以填满它，从而延迟其他GPU内核（蓝色块）的执行，导致Job-A的性能不佳。\n这种干扰主要来自于缺乏控制GPU内核执行频率的能力。为了解决这个问题，我们在DL框架中引入了一个GPU运算器管理器（图8c）。\n现有的DL框架一旦满足了GPU运算器的控制依赖性，就会在GPU运算器中发布GPU内核。在如图8c所示，第三个CPU操作符没有被阻止，然而，第四个操作符被延迟了，因为它依赖于第二个GPU操作符，它的执行被GpuOpManager延迟了。\n     Collaborative Scheduler   AntMan的整体架构\n \rimage-20220905152947633\r AntMan采用了一个分层结构  一个全局调度器负责job 调度 每个工作服务器都包含一个本地协调器，负责通过考虑DL框架报告的统计数据，使用动态资源扩展的基元管理作业的执行   AntMan是为多租户GPU集群设计的。  在多租户集群中，每个租户通常拥有一定的资源，被注释为资源配额（即GPU的数量），这是可以分配给该租户的作业的并发性能保证资源。 每个租户的GPU资源配额之和小于等于一个GPU集群的总容量。   在AntMan中，工作被分为两种，由全局调度器应用不同的调度策略  资源保证型工作：资源保障型作业会消耗其相应租户的一定数量的GPU资源配额。AntMan确保资源保证作业的性能应该与独占执行的性能一致。 机会型工作：机会型作业则不会。      AntMan各模块的运作方式\n 调度决策可以被视为一个自上而下的控制流  在AntMan中，与传统的集群调度器类似，调度决策由全局调度器派发给本地协调器 本地协调器使用动态缩放机制对GPU资源进行内省式调度，以达到DL训练作业的目的   数据统计流信息由本地协调器的统计模块收集，并以自下而上的方式汇总到集群统计模块上  信息  硬件信息  GPU利用率 GPU内存使用率   DL框架报告的详细作业信息  小型批次持续时间 峰值内存使用率 最小内存使用率 主机内存消耗等     这些信息可以帮助全局调度器做出作业调度决策  峰值内存和最小内存使用量是用来指示可以快速提供的GPU内存大小 批处理时间显示GPU内存多久可以用于另一个DL训练作业     当作业在GPU服务器上启动，本地调度器管理其端到端执行  由于DL训练作业的负载波动，本地协调器以自省(introspective)的方式行事，对DL框架进行持续的作业控制 它从硬件和DL框架中收集所有作业的统计数据 -\u0026gt; 使用我们在第3.1节中介绍的新原语 \u0026ndash;\u0026gt; 通过资源使用调整（例如，收缩GPU内存）\u0026ndash;\u0026gt; 来控制作业性能      Scheduling Policy   目标\n  由于集群上的负载和作业的资源需求不断波动，在提供公平性（如确保DL作业的SLA，保证资源）和实现高资源利用率（如GPU利用率）之间存在着固有的矛盾。 普遍的生产型DL集群调度器经常以某些方式用公平性换取效率。  例如，空闲资源被分配给超额配置的租户。 然而，这样的GPU资源在没有抢占的情况下很难拿回来。一般来说，抢占很少被使用，因为它使正在运行的作业失败，同时浪费了昂贵的GPU周期。 此外，还报告了歧视大型作业的失序行为（即分配更多的GPU），导致倾向于小型作业的不公平。      首要目标：多租户公平性  AntMan通过在全局调度器和本地协调器中实施的政策实现了公平性 这些政策由动态扩展机制提供支持。   第二优先：提高集群效率，从而实现更高的吞吐量  AntMan中还引入了GPU机会主义工作，以窃取GPU中的空闲周期，从而最大限度地提高集群的利用率。      全局调度器：维护着工作到达的多个租户队列，决定为工作分配的GPU的位置\n  调度策略\n 对于资源保证型工作和机会型工作，AntMan应用不同的调度策略，如算法1所示。 \rimage-20220905153001724\r findNodes是一个函数，它返回满足工作请求的节点和GPU候选者，并有一个可选的参数来指定约束。 全局调度器在有足够的GPU资源的情况下公平地分配资源保证作业。 除此之外，资源保证作业还可以使用空闲的GPU资源来最大化作业性能 。 如果一个作业的资源请求只能部分满足，全局调度器就会为这个作业保留资源。 保留的资源将永远不会被其他资源保证的作业占用，但是它们可以被机会主义作业所利用。    机会主义作业\n 默认情况下，全局调度器将估计没有设置GPU配额的作业的排队时间。排队时间长的作业将被自动作为机会主义作业执行。 目的：为了最大限度地利用自由资源。 它通过考虑实际的GPU利用率在GPU上分配机会主义作业。只有在过去10秒内利用率**低于M（目前设定为80%）**的GPU可以被选为候选。 在最空闲的候选人上分配机会主义作业（即minLoadNodes，第9-10行）。 分配在同一个GPU上的作业由本地协调者管理    AntMan默认会自动选择机会主义作业，但它也允许用户在提交时手动确定作业类型\n 明确指定为资源保证作业，以确保SLA 一个作业也可以被指定为机会主义作业，永远不会占用租户的资源配额   在实践中，用户通常以机会主义模式提交作业，以避免潜在的排队延迟，目的是进行调试和超参数调整，这都是由早期反馈驱动的。\n     本地调度器：协作执行共享GPU上的作业\n  如何在共享执行中确保资源保证作业的性能\n 一个GPU只会分配给一个资源保证作业，因为它消耗GPU配额 本地协调者首先限制机会主义工作使用GPU，防止资源保证工作受到干扰 在启动DL训练作业时，需要由DL框架初始化GPU设备  如果GPU处于高负荷状态，则需要更多时间。（初始化时占用更多资源） 一旦资源保证作业稳定执行，本地协调器将把剩余的GPU内存分配给机会主义作业。   通过监测作业性能（即小批量时间），在不干扰资源保证作业的情况下，逐步增加机会主义作业的GPU计算单元使用量 同样，当一个机会主义作业到达共享GPU时，本地协调器在不影响资源保证作业的情况下，以阶梯式的方式提高其GPU资源使用率。    如何处理资源保证作业的资源需求激增\n 为了意识到动态的资源需求，本地协调器监测DL框架报告的指标 当一个资源保证作业增加了GPU内存需求时，由于有了通用内存，张量被暂时使用主机内存存储。 本地协调者缩减其他机会主义作业的GPU内存使用量，并提高资源保证作业的GPU内存限制，以恢复其性能。 这对GPU计算单元的使用协调是类似的。 🚨AntMan依靠应用层面的指标（即迷你批处理时间）来表明资源保证作业的性能。如果它观察到资源保证作业的性能不稳定，它就会采取悲观的策略来限制其他机会主义作业对GPU资源的使用。    当一个GPU只被机会主义工作所共享时，最大限度地提高聚合工作的性能。\n  如果只有一个机会主义作业，那么GPU资源就可以被这个作业充分利用，而没有任何约束。\n  有时，一个GPU有可能被多个机会主义工作占用。\n  AntMan通过最大限度地提高GPU内存效率来优化聚合作业的性能。\n  在启用动态缩放机制后，我们发现不同的工作负载在内存限制带来的性能下降方面表现出不同的敏感性\n   \rimage-20220905153042457\r\n  如图10所示，\n SR模型即使在其设备内存减少90%的情况下，也只遭受了大约25%的性能下降 Cifar10数据集上的VGG16[43]模型（VGG）即使在设备内存减少一半后，也能保持其大部分的原始性能。 ImageNet数据集（ResNet）上的ResNet50[22]对内存缩减很敏感；10%的内存缩减会带来60%以上的速度下降。       当机会主义作业的总的GPU内存需求超过了GPU的内存容量时\n 将GPU内存分配给最能提高作业性能（Normalized Performance）的作业          Job 升级\n 机会主义工作虽然以best effort执行， 但这是在没有SLA保证的情况下。 全局调度器会在有足够资源的情况下升级这些作业，以快速完成它们。 全局调度器通知本地协调器，将其标记为资源保证作业，并消耗租户的GPU配额来完成作业升级。    对于分布式同步DL训练来说，部分升级没有帮助，因为一个工作者的性能下降可能会广播到整个作业。 因此，全局调度器检查所有GPU是否都被机会主义工作填满。 一旦所有的任务实例都准备好升级，并且资源配额足够，AntMan更愿意将机会主义工作升级，而不是新启一个工作。     Implementation Deep Learning Framework  动态缩放机制在两个流行的深度学习框架中实现  Pytorch Tensorflow   DL框架的修改主要体现在三个部分：  内存分配器  为了实现动态的通用内存，(tensorflow ::BFCAllocator, PyTorch::CUDACachingAllocator）被修改以引入可调整的内存上限。内存分配器会跟踪内存分配的总字节数，并在总字节数超过上限时触发内存不足。 此外，还为内存分配器引入了一个新的接口，允许在任何时候清空缓存内存。 还增加了一个新的通用内存分配器UniversalAllocator，以包裹GPU内存分配器和主机内存分配器（即使用cudaHostMalloc进行内存分配）。  当张量的请求触发了内存分配时，UniversalAllocator试图使用GPU内存分配器来分配内存， 如果GPU内存剩余不足，则将CPU内存分配器作为备份。 🚨UniversalAllocator维护了一个集合数据结构，记录了由GPU分配的内存区域的指针，用来对内存指针进行分类，以便于回收。     执行器  为了实现动态计算单元的扩展，在DL框架中引入了一个带有运算器处理队列的GpuOpManager，它在一个独立的线程中运行。 TensorFlow的运算器被相应地修改，以插入GPU Op到GpuOpManager队列中，从而将GPU运算器的执行专门交给它。 GpuOpManager可能会根据计算能力的有限百分比来延迟GPU运算符的实际执行。   接口   内存使用模式的统计数据和执行信息被汇总到本地协调器上  DL框架和本地协调器通过文件系统进行通信 他们都有一个监控线程来检查文件，以接收工作统计数据或控制信号 为了最大限度地减少内存管理的开销，内存的动态缩放是在mini-batch的边界（session.run()的结束）触发的    Cluster Scheduler  在Kubernetes上实现了一个自定义调度器，作为评估AntMan的原型。  Kubernetes负责集群管理和执行Docker容器中的作业。 我们的全局调度器使用Python APIs来监控Kubernetes的API服务器中的事件，以便进行调度。 本地协调器作为DaemonSet部署在Kubernetes中。每个协调器监控文件系统的某些路径，以收集每个作业的报告信息。 汇总的作业和设备信息存储在ETCD中，这是Kubernetes中内置的分布式键值存储。因此，全局调度器在做调度决策时直接读取ETCD中的状态。    Evaluation Benchmark Trace Experiment Cluster Experiment Ralated Work Conclusion 参考资料\n 论文地址：AntMan: Dynamic Scaling on GPU Clusters for Deep Learning | USENIX 代码地址：https://github.com/alibaba/GPU-scheduler-for-deep-learning 参考：OSDI'20 论文赏：ANTMAN: DYNAMIC SCALING ON GPU CLUSTERS FOR DEEP LEARNING | 高策 (gaocegege.com)  ","date":"2022-08-29T15:41:42+08:00","image":"https://cdn.jsdelivr.net/gh/Tweakzx/ImageHost@main/img/20220829154241.png","permalink":"https://tweakzx.github.io/p/antman%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/","title":"AntMan论文阅读笔记"},{"content":"《GaiaGPU：Sharing GPUs in Container Clouds》论文笔记 Abstract  对于云服务的提供商， 如何在容器间共享GPU， 是一个有吸引力的问题  容器的轻量与伸缩性 GPU强大的并行计算能力 在云环境，容器需要使用一个或多个GPU来满足资源需要的同时， 容器独占式的GPU往往使用率很低   我们提出GaiaGPU，能够在容器间共享显存和算力  将物理GPU划分为多个虚拟GPU 采用弹性资源分配和动态资源分配来提高资源利用率 实验结果显示， 有效的实现了容器间资源的分配和隔离的同时，平均只增加了1.015%的开销。    Introduction  容器化是一种虚拟化技术  涉及到量身定制一个标准操作系统，方便它在一个物理机上运行由多个用户处理的不同应用程序 与VM模拟底层硬件不同  容器模拟的是操作系统 轻量，可伸缩，易部署 微服务打包与发布应用的事实标准   云服务提供商整合容器编排框架（如k8s）到基础架构中来提供容器云   GPU 图像处理单元  有很强的并行处理能力  因为一个芯片上集成了数以千计的计算核 GPU被广泛用于计算密集型任务，以加快计算 随着技术的发展趋势，现代GPU内将集成入越来越多的计算资源   CUDA是多功能GPU最流行的平台，提供了API方便GPU的使用 卓越的性能吸引了很多云提供商将GPU引入云环境  在云环境中，部署在容器中的一个应用程序可能需要一个或多个GPU才能执行， 而另一方面，应用程序的专用GPU资源导致资源不足。 因此，如何在不同的容器中共享GPU对大多数云提供商都非常感兴趣     GPU虚拟化技术是在隔离的虚拟环境（例如VM， 容器）之间共享GPU的技术  多数的GPU虚拟化技术应用于VM， 容器间的虚拟化技术还在起始阶段 现阶段的基于容器的GPU虚拟化技术有以下局限性  需要特定的硬件设备（NVIDIA GRID） 将一整个GPU分配给单个容器， 不能共享 （NVIDIA Docker） 容器间只能共享GPU显存 （ConvGPU） 只支持单个GPU （ConvGPU）     我们提出GaiaGPU，能够在容器间透明地共享显存和算力  用户不用修改容器镜像来共享底层GPU  我们使用k8s的device plugin 框架将物理GPU划分为多个虚拟GPU   每个镜像可以按需分配一个或者多个vGPU 提供了两者方式在运行时更改镜像资源  弹性资源分配：暂时改变资源 动态资源分配：永久改变资源     vGPU包括GPU显存和计算资源  共享显存  容器包含GPU显存的一小部分 vGPU分配的是GPU的物理内存   共享计算资源  共享计算资源意味着每个容器都拥有GPU线程的一部分以并行执行计算。 VGPU的计算资源由GPU的利用率衡量（采样时段内， 容器使用GPU的时间比例）     总结：本文做了如下贡献  提出了GaiaGPU：一种在容器间透明共享显存与算力的方法 采用弹性分配和动态分配的方式提高了资源的利用率 进行了四个实验来验证GaiaGPU的性能。结果：实现了容器间资源的分配和隔离的同时，平均只增加了1.015%的开销。    Related Work GPU虚拟化   被应用于在多个虚拟环境之间分享GPU， 极大地提高了应用性能\n  现存的多数GPU虚拟化技术基于VM，主要有三种虚拟化GPU\n API remoting  vCUDA 和 rCUDA 创建GPU的封装库-\u0026gt;劫持GPU调用-\u0026gt;将重定向到host   para and full virtualization  GPUvm GPUvm将GPU显存和MMIO（存储器映射输入输出）分成几片，将片分给VM   硬件支持的虚拟化  NVIDIA GRID 硬件虚拟化，创建虚拟GPU，挂在容器      与VM相比， 容器使用主机的操作系统-\u0026gt;容器可以直接使用宿主机的GPU驱动-\u0026gt;性能接近原生环境\n NVIDIA GRID  需要特定的硬件和与虚拟GPU要有相同的资源配置 一个容器只能分配一个虚拟GPU   NVIDIA Docker  使得Docker镜像可以使用GPU 允许GPU驱动对CUDA镜像不感知 提供了一个命令行的封装-\u0026gt;当容器启动时可以挂载driver的用户态组件和GPU设备文件 不能共享：只能把一整个GPU分配给一个容器   ConvGPU  容器间共享GPU显存 它拦截了CUDA库来管理每个镜像显存的分配和回收 仅支持分享显存 而且只能虚拟化单个物理GPU   GaiaGPU  软件层虚拟化，没有硬件限制 每个虚拟GPU的资源可以是不一样的 一个容器可以分配多个虚拟GPU 可以同时共享显存和计算资源 可以虚拟化多个物理GPU      Device Plugin  致力于征聘各种计算资源（GPUs， NICs， FPGAs）供集群使用 无需改变k8s的核心代码 工作流  资源发现  实现Device Plugin 通过gRPC将device注册到Kubelet 成功注册后，device plugin发送设备列表 Kubelet负责将这个扩展资源推广给Master   资源分配  用户在容器的specification中请求设备 master的scheduler选择一个k8s节点的device plugin发送device请求 device plugin分配对应的设备给容器   \rimg\r   Vaucher通过利用设备插件框架来实现SGX（Software Guard Extensions）设备虚拟化，  该插件框架修改了Kubelet和SGX代码以限制虚拟SGX设备的设备内存的使用 仅处理内存资源 对内存施加严重限制   GaiaGPU也采用了device plugin框架以在容器之间共享资源  对资源采用弹性限制而不是硬限制-\u0026gt;来改善利用率    Design And Implementation 设计与实现  目标：在容器间共享显存与计算资源，使用最小的成本获得最大的提升 挑战：  透明性：  GaiaGPU不应该修改k8s的代码或者容器镜像 使用共享GPU就如同使用物理GPU一样   低开销  使用共享GPU的性能尽可能接近使用物理GPU   隔离  GaiaGPU应该管理GPU资源在每个容器的分配与回收 共享GPU时容器之间完全隔离     结构：  \rimage-20220828143547571\r 两层资源管理  host层：  GPU Manager负责创建vGPUs GPU Scheduler 负责分配物理GPU资源到vGPUs   容器层  vGPU Library负责管理具体容器的GPU资源     组件  GPU Manager  device plugin：运行在host上负责创建vGPUs，使用gRPC与Kubelet通信 \rimage-20220828171002587\r Register：GPU Manager将自身注册到Kubelet以通知其存在 ListAndWatch：成功注册后，Kubelet调用ListAndWatch获取设备信息List  显存：256M 作为一个单元， 每个单元都被称作一个vmemory设备 计算资源：一个GPU被分作100份vprocessor设备， 每个vprocessor都有百分之一的利用率   Allocate：  映射过程  Kubelet发送随机选择的设备IDs到GPU Manager GPU Manager根据得到的设备IDs计算所需的物理GPU资源 GPU Manage 发送一个请求到 GPU Scheduler GPU Scheduler 返回要分配给容器的物理GPU   映射完成后，GPU manager返回一个allocateResponse， 包含获取分配到的设备的Configurations  容器的环境变量 挂载到容器的目录和文件 分配的设备   Kubelet将这些配置发送到容器运行时     GPU Scheduler  负责处理GPU Manager发来的调度请求 基于拓扑树分配GPU，树的根节点是host， 树的叶节点是物理GPU 当所需要的资源少于一个物理GPU，分配策略会最大程度减少资源碎片 当所需的资源等于一个物理GPU时，采用了最小化单叶节点（即没有兄弟姐妹节点的叶子节点）的分配策略。 当所需的资源不止一个物理GPU时，分配策略的目标是最大程度地降低GPU的通信成本。通信成本取决于两个GPU的连接模式。   vGPU Manager  运行在host，传递容器配置并且监管分配了vGPUs的容器 当容器申请GPU资源时，GPU Manager将配置发送给vGPU Manager，例如  需要的GPU资源 该容器的name   接收到配置后，在主机上为容器命创建一个唯一的路径  路径名为容器名 这个路径包含在allocateResponse里 容器的配置也包含在这个路径里，所以可以通过Kubelet传递到容器   vGPU Manager 和 vGPU Library是 服务器-客户端模式  vGPU Manager 维护一个活着的且分配了GPU资源的容器的list 会定期检查这些容器是否存活 如果容器死了，从list中移除这个容器的信息，并且删除目录     vGPU Library  运行在容器中，管理容器的GPU资源 在容器第一次执行GPU程序时被加载 启动后vGPU Libraray 向 vGPU Manager注册自身 利用LD_LIBRARY_PATH机制拦截CUDA库中内存与计算相关的API  LD_LIBRARY_PATH是一个linux系统的环境变量 可以影响程序的runtime link 允许某些路径先于standard set of directories（？标准库目录？）加载 \rimage-20220828222012346\r   当容器需要的GPU资源超出它申请的资源时，为了避免耗尽整个GPU，有两种资源限制策略  硬限制（hard limiit）：如果容器资源消耗量超过配额，就不再给该容器分配资源 弹性限制（elastic limit）：如果容器资源消耗量超过配额，但是系统中还有空闲资源，那么该容器仍然能够得到更多的资源   内存资源的限制采用硬限制策略， 因为  内存资源大小能决定一个程序能否运行，但对运行的效率影响较小 GPU是计算设备，它们采用一次性资源分配策略。仅在获取所有内存资源后才可以执行应用程序，并且在完成内存之前不会释放。如果使用弹性内存分配，则具有较大内存需求的应用程序将饿死 撤回过度分配的内存资源的唯一方法是通过抛出out-of-memory exception来杀死该过程   计算资源采用弹性限制策略，因为  计算资源对程序运行的影响很大 计算资源（GPU 线程）在执行之后会立刻释放掉         总结：  Step 1：GPU Manager向Kubelet注册自身，并报告vGPU的信息（ListAndWatch） Step 2：Kubelet接收到来自Master的创建一个GPU容器的请求 Step 3：Kubelet发送一个allocateRequest到GPU Manager Step 4：GPU Manager发送一个vGPU调度请求到GPU Scheduler，GPU Scheduler根据调度策略选择实际提供资源的物理GPU。如果调度成功返回一个包含该物理GPU的信息的reponse Step 5：GPU Manager将容器配置信息发送到vGPU Manager Step 6：GPU Manager将容器环境变量，挂载信息和设备信息通过allocateResponse返回给Kubelet Step 7：Kubelet根据allocateResponse创建并且初始化一个容器 Step 8：vGPU Library向vGPU Manager注册自身并且管理其所在容器的GPU资源 Step 9：vGPU Manager持续监控GPU容器状态 \rimage-20220828143547571\r    优化   容器的资源不仅会影响应用程序的性能，而且还会确定应用程序的状态 用户在创建容器时无法准确估算所需的资源 因此，我们提供两种方法来更改运行时容器的资源。弹性资源分配会暂时修改容器的计算资源限制，而动态资源分配永久改变了容器的资源。     弹性分配策略\n 目的是使用闲置的计算资源以提高资源利用率 \rimage-20220828224059056\r nanosleep()是Linux内核函数，会挂起当前线程等待一段时间或者直到接收到调用当前线程的信号（Line 2） 为了防止过载， $GU_{max}$ 默认的最大值是90% （Line 3） 如果物理GPU计算卡仍然有空闲资源，也就是说GU free \u0026gt; 0，即使容器的资源请求已经超出其配额，vGPU Library也会继续给容器分配计算资源（Line 4-5）。如果系统没有剩余的空闲资源（*GU free \u0026lt;= 0*）并且容器的消耗的资源大于其配额，vGPU Library会逐渐收回超额（over-allocated）资源（Line 6-7） 超额资源的回收采用非抢占式策略（non-preemptive strategy），就是说会等到容器中占用线程的核函数执行完后再回收线程资源。CU cores*可以被理解为一种token，容器执行核函数时需要消耗该token，当核函数执行完成释放线程资源时容器又回重新拥有该token。CU cores的初始值等于容器的计算资源配额，CU cores为零时（系统没有空闲的资源，并且该容器的计算资源配额都正在被用于执行核函数），vGPU Library不会再给容器分配任何计算资源，直到容器的CU cores大于零（其他容器释放了空闲资源，或者该容器有核函数完成释放了资源，容器重新获得CU cores*） 弹性分配的样例  \rimage-20220828233026263\r 首先，容器A申请了0.3个GPU，并且被GPU Scheduler调度到了一个完全空闲的GPU上 由于GPU完全空闲，所以容器A会逐渐占用所有的空闲资源，默认最大可占用90% 此时容器B申请了0.7个GPU，也被调度到了此GPU上，但是由于容器A占用了所有的空闲资源，所以需要从容器A回收超额线程资源并分配给容器B 重复经过几次资源的重新分配，容器A和容器B所占用的资源与其资源配额相同      动态分配策略\n 动态资源分配会修改容器资源，包括内存和计算资源，而无需停止容器。 动态资源分配旨在解决两个问题  在硬限制下更新容器的内存和计算资源 在弹性限制下将内存资源添加到容器中   vGPU Library 通过将容器的资源配置与容器的实际使用进行比较来限制容器资源 要永久更改容器的资源：修改容器的资源配置—\u0026gt;通知GPU Scheduler-\u0026gt;更新相应的物理GPU分配    Experiments \u0026hellip;\nConclusion \u0026hellip;\n参考资料   论文地址 https://ieeexplore.ieee.org/abstract/document/8672318\n  Github开源代码 https://github.com/tkestack/gpu-manager\n  ","date":"2022-08-26T17:20:32+08:00","image":"https://cdn.jsdelivr.net/gh/Tweakzx/ImageHost@main/img/20220826142857.png","permalink":"https://tweakzx.github.io/p/gaiagpu-%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/","title":"GaiaGPU 论文阅读笔记"},{"content":"在ubuntu上k8s集群部署实践 一、机器配置 配置主机名 sudo hostnamectl set-hostname \u0026#34;k8s-master\u0026#34; // Run this command on masternode cat /etc/hostname sudo hostnamectl set-hostname \u0026#34;k8s-node1\u0026#34; // Run this command on node-0 sudo hostnamectl set-hostname \u0026#34;k8s-node2\u0026#34; // Run this command on node-1 配置/etc/hosts sudo vi /etc/hosts 10.1.13.106 k8s-master #10.1.13.107 k8s-node1 #10.1.13.108 k8s-node1 配置免密登录 想让机器 A 访问机器 B，就把机器 A 的公钥放到机器 B 的~/.ssh/authorized_keys 文件里就行了。\n首先我们在worker上生成一个密钥，输入下述命令后一路回车即可：\nssh-keygen 然后登录master，并依次输入下述两条命令将其复制并写入到master的authorized_keys中，注意我下面的scp命令中使用了worker别名，要提前进行配置：\n# 复制到 master 主机 scp root@worker:~/.ssh/id_rsa.pub /home # 写入到 authorized_keys 中 cat /home/id_rsa.pub \u0026gt;\u0026gt; ~/.ssh/authorized_keys 然后再次使用ssh worker登录就可以发现直接连接上而不需要密码了。\n关闭防火墙 sudo systemctl stop firewalld sudo systemctl disable firewalld 禁用swap 这个swap其实可以类比成 windows 上的虚拟内存，它可以让服务器在内存吃满的情况下可以保持低效运行，而不是直接卡死。但是 k8s 的较新版本都要求关闭swap。所以咱们直接动手，修改/etc/fstab文件：\nsudo vi /etc/fstab 你应该可以看到如下内容，把第二条用#注释掉就好了，注意第一条别注释了，不然重启之后系统有可能会报file system read-only错误。\nUUID=e2048966-750b-4795-a9a2-7b477d6681bf / ext4 errors=remount-ro 0 1 # /dev/fd0 /media/floppy0 auto rw,user,noauto,exec,utf8 0 0 然后输入reboot重启即可，重启后使用top命令查看任务管理器，如果看到如下KiB Swap后均为 0 就说明关闭成功了。\n关闭swap之后使用top命令看到 KiB Swap 全部为0\n\rimage-20220613000133107\r\n上面说的是永久关闭swap内存，其实也可以暂时关闭，使用swapoff -a命令即可，效果会在重启后消失。\n禁用Selinux sudo apt install selinux-utils setenforce 0 确保时区和时间正确 sudo timedatectl set-timezone Asia/Shanghai sudo systemctl restart rsyslog sudo apt-get install ntpdate –y sudo ntpdate time.windows.com 配置net.bridge.bridge-nf-call-iptables cat \u0026lt;\u0026lt;EOF | sudo tee /etc/modules-load.d/k8s.conf br_netfilter EOF cat \u0026lt;\u0026lt;EOF | sudo tee /etc/sysctl.d/k8s.conf net.bridge.bridge-nf-call-ip6tables = 1 net.bridge.bridge-nf-call-iptables = 1 EOF sudo sysctl --system 设置rp_filter的值 sudo vi /etc/sysctl.d/10-network-security.conf # 将下面两个参数的值从2修改为1 # net.ipv4.conf.default.rp_filter=1 # net.ipv4.conf.all.rp_filter=1 sudo sysctl --system 二、安装docker docker 是 k8s 的基础，在安装完成之后也需要修改一些配置来适配 k8s ，所以本章分为 docker 的安装 与 docker 的配置 两部分。如果你已经安装并使用了一段时间的 docker 了话，建议使用docker -v查看已安装的 docker 版本，并在 k8s 官网上查询适合该版本的 k8s 进行安装。这一步两台主机都需要进行安装。\n安装docker sudo apt install docker.io sudo apt install docker.io=18.09.1-0ubuntu1 启动docker sudo systemctl start docker 配置docker sudo mkdir -p /etc/docker sudo tee /etc/docker/daemon.json \u0026lt;\u0026lt;-\u0026#39;EOF\u0026#39; { \u0026#34;registry-mirrors\u0026#34;: [\u0026#34;https://n73pm3wf.mirror.aliyuncs.com\u0026#34;], \u0026#34;exec-opts\u0026#34;: [ \u0026#34;native.cgroupdriver=systemd\u0026#34; ] } EOF sudo systemctl daemon-reload sudo systemctl restart docker 设置开机自启动 $ sudo systemctl enable docker 或 $ sudo systemctl enable docker.service --now 验证docker systemctl status docker docker --version docker info | grep Cgroup 修改后的 docker cgroup 状态，发现变为systemd即为修改成功。\n重启docker（当有配置改动后执行） sudo pkill -SIGHUP dockerd sudo systemctl restart docker 卸载docker sudo apt-get remove docker.io 三、安装k8s 安装k8s # 使得 apt 支持 ssl 传输 apt-get update \u0026amp;\u0026amp; apt-get install -y apt-transport-https # 下载 gpg 密钥 这个需要root用户否则会报错 curl https://mirrors.aliyun.com/kubernetes/apt/doc/apt-key.gpg | apt-key add - # 添加 k8s 镜像源 这个需要root用户否则会报错 cat \u0026lt;\u0026lt;EOF \u0026gt;/etc/apt/sources.list.d/kubernetes.list deb https://mirrors.aliyun.com/kubernetes/apt/ kubernetes-xenial main EOF # 更新源列表 apt-get update # 下载 kubectl，kubeadm以及 kubelet # 安装最新版本 apt-get install -y kubelet kubeadm kubectl # 安装指定版本 apt-get install -y kubelet=1.15.1-00 kubeadm=1.15.1-00 kubectl=1.15.1-00 删除已安装的k8s sudo apt-get remove -y --allow-change-held-packages kubeadm kubectl kubelet 查询可安装版本 apt-cache madison kubeadm apt-cache madison kubelet apt-cache madison kubectl apt-cache madison kubernetes-cni 设置不随系统更新而更新 sudo apt-mark hold kubelet kubeadm kubectl 四、初始化master kubeadm init kubeadm init \\ --apiserver-advertise-address=10.10.0.2 \\ --kubernetes-version=1.15.1 \\ --image-repository registry.cn-hangzhou.aliyuncs.com/google_containers \\ --service-cidr=10.96.0.0/16 \\ --pod-network-cidr=10.244.0.0/16 参数解释：\n \u0026ndash;kubernetes-version：指定kubernetes的版本，与上面kubelet，kubeadm，kubectl工具版本保持一致。 \u0026ndash;apiserver-advertise-address：apiserver所在的节点(master)的ip。 \u0026ndash;image-repository=registry.aliyuncs.com/google_containers：由于国外地址无法访问，所以使用阿里云仓库地址 \u0026ndash;server-cidr：service之间访问使用的网络ip段 \u0026ndash;pod-network-cidr：pod之间网络访问使用的网络ip,与下文部署的CNI网络组件yml中保持一致  初始化成功之后你将看到\nYour Kubernetes control-plane has initialized successfully! To start using your cluster, you need to run the following as a regular user: mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/config Alternatively, if you are the root user, you can run: export KUBECONFIG=/etc/kubernetes/admin.conf You should now deploy a pod network to the cluster. Run \u0026#34;kubectl apply -f [podnetwork].yaml\u0026#34; with one of the options listed at: https://kubernetes.io/docs/concepts/cluster-administration/addons/ Then you can join any number of worker nodes by running the following on each as root: kubeadm join 10.10.0.2:6443 --token juojiv.q4gwfmkj4cwgscnt \\  --discovery-token-ca-cert-hash sha256:381b61262d3b174cfce0e5cfbd0b4b171e270c506d82c4d82334d0a4e2c2ac47 初始化失败 重置之后重新初始化\nkubeadm reset 记得保存kubeadm join 命令 kubeadm join 10.10.0.2:6443 --token qc7drh.47mloh5ierij84xi \\  --discovery-token-ca-cert-hash sha256:90f147ef85ae06d9a46bed91d64109abbd697b6878ab9ca16a376e11816f9a0d 如果忘记可以使用下面的命令重新生成\nkubeadm token create --print-join-command 配置kubectl 按照上图中的命令配置，可以直接从命令行中复制\n 非root用户  mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/config # 查看已加入的节点 kubectl get nodes # 查看集群状态 kubectl get cs  root用户  export KUBECONFIG=/etc/kubernetes/admin.conf 部署网络 网络插件可以选择calico或flannel。这里使用Flannel作为Kubernetes容器网络方案，解决容器跨主机网络通信。\n 部署flannel网络  kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml 也可以把这个文件下载到本地，注意修改下图中的Network，与kubeadm inti中的\u0026ndash;pod-network-cidr 10.244.0.0/16参数保持一致，然后\nkubectl apply -f kube-flannel.yml \rimage-20220613013117789\r\n将会看到\npodsecuritypolicy.policy/psp.flannel.unprivileged created clusterrole.rbac.authorization.k8s.io/flannel created clusterrolebinding.rbac.authorization.k8s.io/flannel created serviceaccount/flannel created configmap/kube-flannel-cfg created daemonset.apps/kube-flannel-ds created 查看pod状态，应该全部为running。可能需要等待一段时间\nkubectl get pod --all-namespaces -o wide \rimage-20220613012658569\r\n 部署calico网络  下载yml文件\nwget https://docs.projectcalico.org/v3.11/manifests/calico.yaml vi calico.yaml #修改CALICO_IPV4POOL_CIDR，为10.244.0.0/16（要与kubeadm inti中的\u0026ndash;pod-network-cidr 10.244.0.0/16参数保持一致，默认为192.168.0.0/16\nkubectl apply -f calico.yaml 五、添加worker节点 使用之前保存的kubeadm join命令\nkubeadm join 10.10.0.2:6443 --token ryyy8k.pr8u7cjm4btqdx4v --discovery-token-ca-cert-hash sha256:6b596c66745b162190475b63686ca46c60cc4f39473 然后在master节点上，查看\nkubectl get nodes 可以看到\n\rimage-20220613010009663\r\n六、验证 创建nginx kubectl create deployment nginx-web --image=nginx 获取pod信息 kubectl get pod -o wide \rimage-20220613013920336\r\n可以看到该节点的ip为10.244.1.2\n测试nginx root@k8s-master:/home# curl http://10.244.1.2 可以看到\n\u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;title\u0026gt;Welcome to nginx!\u0026lt;/title\u0026gt; \u0026lt;style\u0026gt; html { color-scheme: light dark; } body { width: 35em; margin: 0 auto; font-family: Tahoma, Verdana, Arial, sans-serif; } \u0026lt;/style\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h1\u0026gt;Welcome to nginx!\u0026lt;/h1\u0026gt; \u0026lt;p\u0026gt;If you see this page, the nginx web server is successfully installed and working. Further configuration is required.\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;For online documentation and support please refer to \u0026lt;a href=\u0026#34;http://nginx.org/\u0026#34;\u0026gt;nginx.org\u0026lt;/a\u0026gt;.\u0026lt;br/\u0026gt; Commercial support is available at \u0026lt;a href=\u0026#34;http://nginx.com/\u0026#34;\u0026gt;nginx.com\u0026lt;/a\u0026gt;.\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;\u0026lt;em\u0026gt;Thank you for using nginx.\u0026lt;/em\u0026gt;\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 删除pod kubectl delete pod nginx-web-xxxxxx -n nginx-web 七、删除节点 首先，确定想要清空的节点的名称。可以用以下命令列出集群中的所有节点:\nkubectl get nodes 接下来，告诉 Kubernetes 清空节点：\nkubectl drain \u0026lt;node name\u0026gt; 一旦它返回（没有报错）， 你就可以下线此节点（或者等价地，如果在云平台上，删除支持该节点的虚拟机）。 如果要在维护操作期间将节点留在集群中，则需要运行：\nkubectl uncordon \u0026lt;node name\u0026gt; 然后告诉 Kubernetes，它可以继续在此节点上调度新的 Pods。\n","date":"2022-06-13T14:57:42+08:00","image":"https://cdn.jsdelivr.net/gh/Tweakzx/ImageHost@main/img/20220823230439.png","permalink":"https://tweakzx.github.io/p/ubuntu%E5%AE%89%E8%A3%85k8s%E9%9B%86%E7%BE%A4/","title":"Ubuntu安装k8s集群"},{"content":"题目描述 请你来实现一个 myAtoi(string s) 函数，使其能将字符串转换成一个 32 位有符号整数（类似 C/C++ 中的 atoi 函数）。\n函数 myAtoi(string s) 的算法如下：\n 读入字符串并丢弃无用的前导空格 检查下一个字符（假设还未到字符末尾）为正还是负号，读取该字符（如果有）。 确定最终结果是负数还是正数。 如果两者都不存在，则假定结果为正。 读入下一个字符，直到到达下一个非数字字符或到达输入的结尾。字符串的其余部分将被忽略。 将前面步骤读入的这些数字转换为整数（即，\u0026ldquo;123\u0026rdquo; -\u0026gt; 123， \u0026ldquo;0032\u0026rdquo; -\u0026gt; 32）。如果没有读入数字，则整数为 0 。必要时更改符号（从步骤 2 开始）。 如果整数数超过 32 位有符号整数范围 [−231, 231 − 1] ，需要截断这个整数，使其保持在这个范围内。具体来说，小于 −231 的整数应该被固定为 −231 ，大于 231 − 1 的整数应该被固定为 231 − 1 。 返回整数作为最终结果。  注意：\n  本题中的空白字符只包括空格字符 ' ' 。\n  除前导空格或数字后的其余字符串外，请勿忽略 任何其他字符。\n  示例 1：\n 输入：s = \u0026ldquo;42\u0026rdquo; 输出：42 解释：加粗的字符串为已经读入的字符，插入符号是当前读取的字符。 第 1 步：\u0026ldquo;42\u0026rdquo;（当前没有读入字符，因为没有前导空格） ^ 第 2 步：\u0026ldquo;42\u0026rdquo;（当前没有读入字符，因为这里不存在 \u0026lsquo;-\u0026rsquo; 或者 \u0026lsquo;+'） ^ 第 3 步：\u0026ldquo;42\u0026rdquo;（读入 \u0026ldquo;42\u0026rdquo;） ^ 解析得到整数 42 。 由于 \u0026ldquo;42\u0026rdquo; 在范围 [-231, 231 - 1] 内，最终结果为 42 。\n 示例 2：\n 输入：s = \u0026quot; -42\u0026quot; 输出：-42 解释： 第 1 步：\u0026quot; -42\u0026quot;（读入前导空格，但忽视掉） ^ 第 2 步：\u0026quot; -42\u0026quot;（读入 \u0026lsquo;-\u0026rsquo; 字符，所以结果应该是负数） ^ 第 3 步：\u0026quot; -42\u0026quot;（读入 \u0026ldquo;42\u0026rdquo;） ^ 解析得到整数 -42 。 由于 \u0026ldquo;-42\u0026rdquo; 在范围 [-231, 231 - 1] 内，最终结果为 -42 。\n 示例 3：\n 输入：s = \u0026ldquo;4193 with words\u0026rdquo; 输出：4193 解释： 第 1 步：\u0026ldquo;4193 with words\u0026rdquo;（当前没有读入字符，因为没有前导空格） ^ 第 2 步：\u0026ldquo;4193 with words\u0026rdquo;（当前没有读入字符，因为这里不存在 \u0026lsquo;-\u0026rsquo; 或者 \u0026lsquo;+'） ^ 第 3 步：\u0026ldquo;4193 with words\u0026rdquo;（读入 \u0026ldquo;4193\u0026rdquo;；由于下一个字符不是一个数字，所以读入停止） ^ 解析得到整数 4193 。 由于 \u0026ldquo;4193\u0026rdquo; 在范围 [-231, 231 - 1] 内，最终结果为 4193 。\n 提示：\n 0 \u0026lt;= s.length \u0026lt;= 200 s 由英文字母（大写和小写）、数字（0-9）、\u0026rsquo; \u0026lsquo;、'+'、'-\u0026rsquo; 和 \u0026lsquo;.\u0026rsquo; 组成  来源：力扣（LeetCode） 链接：https://leetcode-cn.com/problems/string-to-integer-atoi\n题解 大家可以自行去看leetcode的官方题解，就是用一个自动机来解决这个问题。我第一次用Go来解决这个问题，所以决定记录下来\ntype Automaton struct{ state string sign int ans int table map[string][]string } func(a *Automaton) init(){ //因为Go不能设置类型变量的初始值（我没找到相关代码），所以我用了初始化函数来代替  a.state = \u0026#34;start\u0026#34; a.sign = 1 a.ans = 0 a.table = map[string][]string{ \u0026#34;start\u0026#34; : []string{\u0026#34;start\u0026#34;,\u0026#34;signed\u0026#34;,\u0026#34;in_number\u0026#34;,\u0026#34;end\u0026#34;}, \u0026#34;signed\u0026#34; : []string{\u0026#34;end\u0026#34;,\u0026#34;end\u0026#34;,\u0026#34;in_number\u0026#34;,\u0026#34;end\u0026#34;}, \u0026#34;in_number\u0026#34; : []string{\u0026#34;end\u0026#34;,\u0026#34;end\u0026#34;,\u0026#34;in_number\u0026#34;,\u0026#34;end\u0026#34;}, \u0026#34;end\u0026#34; : []string{\u0026#34;end\u0026#34;,\u0026#34;end\u0026#34;,\u0026#34;end\u0026#34;,\u0026#34;end\u0026#34;}, } } func(a *Automaton) get(c byte){ //实现状态转移的方法  a.state = a.table[a.state][a.get_col(c)] switch a.state{ case \u0026#34;in_number\u0026#34;: a.ans = a.ans*10 + int(c-\u0026#39;0\u0026#39;) if a.sign\u0026gt;0{ a.ans = min(a.ans, math.MaxInt32) }else{ a.ans = min(a.ans, -math.MinInt32) } case \u0026#34;signed\u0026#34;: if c == \u0026#39;-\u0026#39;{ a.sign = -1 } } } func(a *Automaton) get_col(c byte ) int{//获得输入字符的类型  switch { case c==\u0026#39; \u0026#39;: return 0 case c==\u0026#39;+\u0026#39;||c==\u0026#39;-\u0026#39;: return 1 case \u0026#39;0\u0026#39;\u0026lt;=c\u0026amp;\u0026amp;c\u0026lt;=\u0026#39;9\u0026#39;: return 2 default: return 3 } } func(a *Automaton) get_ans() int{ //获得结果  return a.sign * a.ans } func myAtoi(s string) int { a := \u0026amp;Automaton{} a.init() for i:=0; i\u0026lt;len(s); i++{ a.get(s[i]) } return a.get_ans() } func min(a,b int) int{ if a\u0026lt;b{ return a } return b } ","date":"2022-03-12T16:59:39+08:00","permalink":"https://tweakzx.github.io/p/%E8%87%AA%E5%8A%A8%E6%9C%BA%E7%9A%84%E5%AE%9E%E7%8E%B0/","title":"自动机的实现"},{"content":"旅行起点 Go 语言之旅 (go-zh.org)\n上方链接是一个Go语言学习的Playground，快点击它，开启一场Go语言之旅吧\n旅行开始 练习：循环与函数 为了练习函数与循环，我们来实现一个平方根函数：用牛顿法实现平方根函数。\n计算机通常使用循环来计算 x 的平方根。从某个猜测的值 z 开始，我们可以根据 z² 与 x 的近似度来调整 z，产生一个更好的猜测：\nz -= (z*z - x) / (2*z) 重复调整的过程，猜测的结果会越来越精确，得到的答案也会尽可能接近实际的平方根。\n在提供的 func Sqrt 中实现它。无论输入是什么，对 z 的一个恰当的猜测为 1。 要开始，请重复计算 10 次并随之打印每次的 z 值。观察对于不同的值 x（1、2、3 \u0026hellip;）， 你得到的答案是如何逼近结果的，猜测提升的速度有多快。\n提示：用类型转换或浮点数语法来声明并初始化一个浮点数值：\nz := 1.0 z := float64(1) 然后，修改循环条件，使得当值停止改变（或改变非常小）的时候退出循环。观察迭代次数大于还是小于 10。 尝试改变 z 的初始猜测，如 x 或 x/2。你的函数结果与标准库中的 math.Sqrt 接近吗？\n（注： 如果你对该算法的细节感兴趣，上面的 z² − x 是 z² 到它所要到达的值（即 x）的距离， 除以的 2z 为 z² 的导数，我们通过 z² 的变化速度来改变 z 的调整量。 这种通用方法叫做牛顿法。 它对很多函数，特别是平方根而言非常有效。）\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;math\u0026#34; ) func Sqrt(x float64) (z float64) { z = float64(1) for math.Abs(z*z-x)\u0026gt;0.000001 { z -= (z*z-x)/(z*2) } return } func main() { fmt.Println(Sqrt(2)) } 练习：切片 实现 Pic。它应当返回一个长度为 dy 的切片，其中每个元素是一个长度为 dx，元素类型为 uint8 的切片。当你运行此程序时，它会将每个整数解释为灰度值（好吧，其实是蓝度值）并显示它所对应的图像。\n图像的选择由你来定。几个有趣的函数包括 (x+y)/2, x*y, x^y, x*log(y) 和 x%(y+1)。\n（提示：需要使用循环来分配 [][]uint8 中的每个 []uint8；请使用 uint8(intValue) 在类型之间转换；你可能会用到 math 包中的函数。）\npackage main import \u0026#34;golang.org/x/tour/pic\u0026#34; func Pic(dx, dy int) [][]uint8 { picture := make([][]uint8,dy) for x:=range picture{ line := make([]uint8,dx) for y:=range line{ line[y] = uint8((x+y)/2) } picture[x] = line } return picture } func main() { pic.Show(Pic) } 练习：映射 实现 WordCount。它应当返回一个映射，其中包含字符串 s 中每个“单词”的个数。函数 wc.Test 会对此函数执行一系列测试用例，并输出成功还是失败。\n你会发现 strings.Fields 很有帮助。\npackage main import ( \u0026#34;golang.org/x/tour/wc\u0026#34; \u0026#34;strings\u0026#34; ) func WordCount(s string) map[string]int { words := strings.Fields(s) ans := make(map[string]int) for _,w :=range words{ //v,ok := ans[w] \tans[w] = ans[w] + 1 } return ans } func main() { wc.Test(WordCount) } 练习：斐波纳契闭包 让我们用函数做些好玩的事情。\n实现一个 fibonacci 函数，它返回一个函数（闭包），该闭包返回一个斐波纳契数列 (0, 1, 1, 2, 3, 5, ...)。\npackage main import \u0026#34;fmt\u0026#34; // 返回一个“返回int的函数” func fibonacci() func() int { first := 2 second := 1 //根据公式倒推出的first和second \treturn func() int{ first = second - first second = second + first //斐波那契公式 \treturn second } } func main() { f := fibonacci() for i := 0; i \u0026lt; 10; i++ { fmt.Println(f()) } } 练习：Stringer 通过让 IPAddr 类型实现 fmt.Stringer 来打印点号分隔的地址。\n例如，IPAddr{1, 2, 3, 4} 应当打印为 \u0026quot;1.2.3.4\u0026quot;。\npackage main import \u0026#34;fmt\u0026#34; type IPAddr [4]byte // TODO: 给 IPAddr 添加一个 \u0026#34;String() string\u0026#34; 方法 func (ip IPAddr) String() string{ return fmt.Sprintf(\u0026#34;%v.%v.%v.%v\\n\u0026#34;,ip[0],ip[1],ip[2],ip[3]) } func main() { hosts := map[string]IPAddr{ \u0026#34;loopback\u0026#34;: {127, 0, 0, 1}, \u0026#34;googleDNS\u0026#34;: {8, 8, 8, 8}, } for name, ip := range hosts { fmt.Printf(\u0026#34;%v: %v\\n\u0026#34;, name, ip) } } 练习：错误 从之前的练习中复制 Sqrt 函数，修改它使其返回 error 值。\nSqrt 接受到一个负数时，应当返回一个非 nil 的错误值。复数同样也不被支持。\n创建一个新的类型\ntype ErrNegativeSqrt float64 并为其实现\nfunc (e ErrNegativeSqrt) Error() string 方法使其拥有 error 值，通过 ErrNegativeSqrt(-2).Error() 调用该方法应返回 \u0026quot;cannot Sqrt negative number: -2\u0026quot;。\n注意: 在 Error 方法内调用 fmt.Sprint(e) 会让程序陷入死循环。可以通过先转换 e 来避免这个问题：fmt.Sprint(float64(e))。这是为什么呢？\n修改 Sqrt 函数，使其接受一个负数时，返回 ErrNegativeSqrt 值。\npackage main import ( \u0026#34;fmt\u0026#34; ) type ErrNegativeSqrt float64 func (e ErrNegativeSqrt) Error() string{ return fmt.Sprintf(\u0026#34;cannot Sqrt negative number: %v\u0026#34;,float64(e)) } func Sqrt(x float64) (float64, error) { if x\u0026gt;0{ return 0, nil }else{ var e ErrNegativeSqrt e = ErrNegativeSqrt(x) return x,e } } func main() { fmt.Println(Sqrt(2)) fmt.Println(Sqrt(-2)) } 练习：Reader 实现一个 Reader 类型，它产生一个 ASCII 字符 'A' 的无限流。\npackage main import \u0026#34;golang.org/x/tour/reader\u0026#34; type MyReader struct{} // TODO: 给 MyReader 添加一个 Read([]byte) (int, error) 方法 func (mr MyReader) Read(buf []byte) (int, error) { for i :=range buf{ buf[i] = \u0026#39;A\u0026#39; } return 1, nil } func main() { reader.Validate(MyReader{}) } 练习：rot13Reader 有种常见的模式是一个 io.Reader 包装另一个 io.Reader，然后通过某种方式修改其数据流。\n例如，gzip.NewReader 函数接受一个 io.Reader（已压缩的数据流）并返回一个同样实现了 io.Reader 的 *gzip.Reader（解压后的数据流）。\n编写一个实现了 io.Reader 并从另一个 io.Reader 中读取数据的 rot13Reader，通过应用 rot13 代换密码对数据流进行修改。\nrot13Reader 类型已经提供。实现 Read 方法以满足 io.Reader。\npackage main import ( \u0026#34;io\u0026#34; \u0026#34;os\u0026#34; \u0026#34;strings\u0026#34; ) type rot13Reader struct { r io.Reader } func ( rot rot13Reader) Read(buf []byte) (int, error){ len,ok := rot.r.Read(buf) for i,v := range buf{ switch{ case (\u0026#39;a\u0026#39;\u0026lt;=v \u0026amp;\u0026amp; v\u0026lt;=\u0026#39;m\u0026#39;)||(\u0026#39;A\u0026#39;\u0026lt;=v \u0026amp;\u0026amp; v\u0026lt;=\u0026#39;M\u0026#39;): buf[i] = v+13 case (\u0026#39;n\u0026#39;\u0026lt;=v \u0026amp;\u0026amp; v\u0026lt;=\u0026#39;z\u0026#39;)||(\u0026#39;N\u0026#39;\u0026lt;=v \u0026amp;\u0026amp; v\u0026lt;=\u0026#39;Z\u0026#39;): buf[i] = v-13 default: } } return len,ok } func main() { s := strings.NewReader(\u0026#34;Lbh penpxrq gur pbqr!\u0026#34;) r := rot13Reader{s} io.Copy(os.Stdout, \u0026amp;r) } 练习：图像 还记得之前编写的图片生成器 吗？我们再来编写另外一个，不过这次它将会返回一个 image.Image 的实现而非一个数据切片。\n定义你自己的 Image 类型，实现必要的方法并调用 pic.ShowImage。\nBounds 应当返回一个 image.Rectangle ，例如 image.Rect(0, 0, w, h)。\nColorModel 应当返回 color.RGBAModel。\nAt 应当返回一个颜色。上一个图片生成器的值 v 对应于此次的 color.RGBA{v, v, 255, 255}。\npackage main import ( \u0026#34;golang.org/x/tour/pic\u0026#34; \u0026#34;image\u0026#34; \u0026#34;image/color\u0026#34; ) type Image struct{ w,h int pixels [][]uint8 } func (self Image) Bounds()(image.Rectangle){ return image.Rect(0, 0, self.w, self.h) } func (self Image) ColorModel()(color.Model){ return color.RGBAModel } func (self Image) At(x int ,y int)(color.Color){ v := self.pixels[y][x] return color.RGBA{v,v, 255, 255} } func Pic(dx, dy int) [][]uint8 { img := make([][]uint8, dy) for y := 0; y \u0026lt; dy; y++ { img[y] = make([]uint8, dx) for x := 0; x \u0026lt; dx; x++ { img[y][x] = (uint8)(x^y) } } return img } func main() { m := Image{256,256,Pic(256,256)} pic.ShowImage(m) } 练习：等价二叉查找树 1. 实现 Walk 函数。\n2. 测试 Walk 函数。\n函数 tree.New(k) 用于构造一个随机结构的已排序二叉查找树，它保存了值 k, 2k, 3k, \u0026hellip;, 10k。\n创建一个新的信道 ch 并且对其进行步进：\ngo Walk(tree.New(1), ch) 然后从信道中读取并打印 10 个值。应当是数字 1, 2, 3, ..., 10。\n3. 用 Walk 实现 Same 函数来检测 t1 和 t2 是否存储了相同的值。\n4. 测试 Same 函数。\nSame(tree.New(1), tree.New(1)) 应当返回 true，而 Same(tree.New(1), tree.New(2)) 应当返回 false。\nTree 的文档可在这里找到。\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;golang.org/x/tour/tree\u0026#34; ) // Walk 步进 tree t 将所有的值从 tree 发送到 channel ch。 func Walk(t *tree.Tree, ch chan int) { dfs(t, ch) close(ch) } func dfs(t *tree.Tree, ch chan int) { if t == nil { return } dfs(t.Left, ch) ch \u0026lt;- t.Value dfs(t.Right, ch) } // Same 检测树 t1 和 t2 是否含有相同的值。 func Same(t1, t2 *tree.Tree) bool { ch1, ch2 := make(chan int), make(chan int) go Walk(t1, ch1) go Walk(t2, ch2) for i := range ch1 { // ch1 关闭后 for循环自动跳出 \tif i != \u0026lt;-ch2 { return false } } return true } func main() { fmt.Println(Same(tree.New(1), tree.New(1))) } 练习：Web 爬虫 在这个练习中，我们将会使用 Go 的并发特性来并行化一个 Web 爬虫。\n修改 Crawl 函数来并行地抓取 URL，并且保证不重复。\n提示：你可以用一个 map 来缓存已经获取的 URL，但是要注意 map 本身并不是并发安全的！\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;sync\u0026#34; ) type Fetcher interface { // Fetch 返回 URL 的 body 内容，并且将在这个页面上找到的 URL 放到一个 slice 中。 \tFetch(url string) (body string, urls []string, err error) } // Crawl 使用 fetcher 从某个 URL 开始递归的爬取页面，直到达到最大深度。  type CrawlRecord struct{ m map[string]int mux sync.Mutex wg sync.WaitGroup } var\tcr = CrawlRecord{m: make(map[string]int)} func Crawl(url string, depth int, fetcher Fetcher) { defer cr.wg.Done() // TODO: 并行的抓取 URL。 \t// TODO: 不重复抓取页面。  // 下面并没有实现上面两种情况： \tif depth \u0026lt;= 0 { return } cr.mux.Lock() cr.m[url]++ cr.mux.Unlock() body, urls, err := fetcher.Fetch(url) if err != nil { fmt.Println(err) return } fmt.Printf(\u0026#34;found: %s %q\\n\u0026#34;, url, body) for _, u := range urls { cr.mux.Lock() if _,ok := cr.m[u]; !ok{ cr.wg.Add(1) go Crawl(u, depth-1, fetcher) } cr.mux.Unlock() } return } func main() { cr.wg.Add(1) Crawl(\u0026#34;https://golang.org/\u0026#34;, 4, fetcher) cr.wg.Wait() } // fakeFetcher 是返回若干结果的 Fetcher。 type fakeFetcher map[string]*fakeResult type fakeResult struct { body string urls []string } func (f fakeFetcher) Fetch(url string) (string, []string, error) { if res, ok := f[url]; ok { return res.body, res.urls, nil } return \u0026#34;\u0026#34;, nil, fmt.Errorf(\u0026#34;not found: %s\u0026#34;, url) } // fetcher 是填充后的 fakeFetcher。 var fetcher = fakeFetcher{ \u0026#34;https://golang.org/\u0026#34;: \u0026amp;fakeResult{ \u0026#34;The Go Programming Language\u0026#34;, []string{ \u0026#34;https://golang.org/pkg/\u0026#34;, \u0026#34;https://golang.org/cmd/\u0026#34;, }, }, \u0026#34;https://golang.org/pkg/\u0026#34;: \u0026amp;fakeResult{ \u0026#34;Packages\u0026#34;, []string{ \u0026#34;https://golang.org/\u0026#34;, \u0026#34;https://golang.org/cmd/\u0026#34;, \u0026#34;https://golang.org/pkg/fmt/\u0026#34;, \u0026#34;https://golang.org/pkg/os/\u0026#34;, }, }, \u0026#34;https://golang.org/pkg/fmt/\u0026#34;: \u0026amp;fakeResult{ \u0026#34;Package fmt\u0026#34;, []string{ \u0026#34;https://golang.org/\u0026#34;, \u0026#34;https://golang.org/pkg/\u0026#34;, }, }, \u0026#34;https://golang.org/pkg/os/\u0026#34;: \u0026amp;fakeResult{ \u0026#34;Package os\u0026#34;, []string{ \u0026#34;https://golang.org/\u0026#34;, \u0026#34;https://golang.org/pkg/\u0026#34;, }, }, } 旅行终点 你可以从安装 Go 开始。\nwget -c https://dl.google.com/go/go1.14.2.linux-amd64.tar.gz -O - | sudo tar -xz -C /usr/local vim /etc/profile export PATH=$PATH:/usr/local/go/bin export GOPROXY=https://goproxy.cn,direct export GO111MODULE=on source ~/.profile go version 一旦安装了 Go，Go 文档是一个极好的 应当继续阅读的内容。 它包含了参考、指南、视频等等更多资料。\n了解如何组织 Go 代码并在其上工作，参阅此视频，或者阅读如何编写 Go 代码。\n如果你需要标准库方面的帮助，请参考包手册。如果是语言本身的帮助，阅读语言规范是件令人愉快的事情。\n进一步探索 Go 的并发模型，参阅 Go 并发模型(幻灯片)以及深入 Go 并发模型(幻灯片)并阅读通过通信共享内存的代码之旅。\n想要开始编写 Web 应用，请参阅一个简单的编程环境(幻灯片)并阅读编写 Web 应用的指南。\n函数：Go 中的一等公民展示了有趣的函数类型。\nGo 博客有着众多关于 Go 的文章和信息。\nmikespook 的博客中有大量中文的关于 Go 的文章和翻译。\n开源电子书 Go Web 编程和 Go 入门指南能够帮助你更加深入的了解和学习 Go 语言。\n访问 go-zh.org 了解更多内容。\n","date":"2022-02-22T17:20:32+08:00","image":"https://go.dev/images/gophers/biplane.svg","permalink":"https://tweakzx.github.io/p/go%E8%AF%AD%E8%A8%80%E4%B9%8B%E6%97%85/","title":"Go语言之旅"},{"content":"PolarDB Serverless论文阅读报告 摘要 数据库管理系统的上云是近期很火的研究趋势，因为这样可以获得更高的弹性，可用性以及更低的成本，传统的独块的数据库架构很难满足这样的要求。高速网络与新的内存技术（例如RDMA）的发展，给分散式数据库带来了可能：它将原先的独块的服务器资源分离解耦到资源池中，再通过高速网络连接起来。下一代的云原生数据库就是为了分散化的数据中心而设计。\nPolarDB Serverless 遵循分散式的设计范式而设计，解耦了计算节点的CPU，内存，存储资源。\n 每种资源可以随需求而独立的增长或缩小，保障可靠性的同时，可以进行多维度的按需供应。 同时采用了优化策略如乐观锁和预取策略来改善性能。 还可以实现更快的故障恢复。  介绍 使用云数据库的三个好处：  按需付费可以使得用户减小开支。 更高的资源弹性可以应对短暂的资源使用高峰期。 更快的升级与更快的错误修复。快速的升级迭代可以保证产品竞争力，错误修复可以在不影响产品可用性的前提下进行。  经典的云数据库的架构  monolithic machine 独块的机器  特点：所有的资源都是紧耦合的 问题：  在进行数据库实例到机器的分发过程中要解决一个装箱问题 总是有碎片化的资源，难以达到高的使用率 运行时不能根据负载调整资源 资源间的命运共享，一个资源的故障会导致其他资源的故障，不能独立透明地修复故障，导致修复时间很长     存算分离的架构：  两种：  virtual machine with remote disk 搭载远程硬盘的虚拟机 shared storage 共享存储   优点  DBaaS可以提高存储池的使用率 共享存储可以进一步减少成本：原数据与只读备份可以共享存储   问题  CPU和内存的装箱问题依旧存在 缺乏灵活可放缩的内存资源 每个只读备份在内存中都要有冗余的内存开销      本文提出了一种新架构，分散架构（disaggragation architecture)  运行在分散的数据中心（DDC），CPU、内存和存储解耦，资源间通过高速网络连接 效果  每一种资源都可以提高其利用率，可以独立地放缩其资源量 解决了资源间的命运共享问题，资源故障可以被独立修复 数据页可以在远程内存池中被共享，所以解决了备份的内存冗余问题    云原生数据库 多数的云数据库是基于共享存储的架构，内存和CPU绑成最小的资源单元，只能按照最小资源单元的粒度来增长和释放资源，这会带来很多的资源浪费。\nPolarDB Serverless则是遵循分散架构的一个云原生数据库\n  引入了多租户可放缩的内存池，可以进行内存页的分配与生命周期管理\n  节点组成：\n 一个 RW node(存原数据页节点) 多个 RO node（存只读备份节点）    面临的挑战\n 添加远程内存之后，系统可以正确地处理事务  当写后读时，系统不应该错过任何一个update。使用缓存失效机制来保证写后所有地节点会更新 在更新B+树地索引的时候，使用global latch全局页锁来保证RO节点不能看到不一致的索引结构 使用读视图来确保RO节点不会读到未提交的事务   高效地执行事务  广泛使用了RDMA操作，尤其是one-sided RDMA verbs 为了提高并发，使用了乐观锁 存储方面使用了page materialization offloading技术，使用redo日志生成page 利用了预取来提高本地命中率   构建可信系统  对不同的节点都设计了策略来处理单点故障 因为内存和存储的状态是解耦的，所以修复崩溃的速度比独块架构要快5.3倍      背景 PolarDB PolarDB是一个基于共享内存架构云原生数据库\n PolarFS是一个持久化的原子操作的可伸缩的分布式共享存储。是统一的存储资源池，其提供虚拟的volume，每个volume划分为10GB大小的chunk分布在不同的节点。每个volume最多10000个chunk，即100T的容量。每个chunk三副本，用parallel raft提供线性一致性。 RW和RO节点之间通过redo日志来同步内存状态，通过LSN（log sequence number）来协调一致性。RW和RO节点上有负责处理SQL语句的处理器和事务引擎（InnoDB，X-Engine），以及一个缓存池来服务查询与事务。 有多个无状态的代理节点负责透明的负载均衡  \rimage-20211222201006368\r\n分散化的数据中心DDC   连接技术\n  在分散化的数据中心，计算节点、内存结点以及存储节点都是由高速网络连接。\n  RDMA（Remote Direct Memory Access）技术给大型的DDC带来了可能\n    层级结构\n 分为三层：spine layer、leaf layer、ToR layer 每一个ToR节点链接48台主机，ToR的交换机分别连接Leaf节点的交换机，然后Leaf的交换机又去链接Spine层的交换机。 每台主机都会配有双端口的RDMA网卡，用于链接两个ToR节点来避免单点故障。 一个leaf 交换机组包含互为备份的同时工作的多个leaf交换机 由一个leaf交换机组管理控制的所有的交换机与服务器称为一个PoD（Point of Delivery）。一个PoD最多有32个leaf交换机。    资源部署方式\n 单个数据库实例所需的内存和存储会部署在一个PoD下 不同实例部署在不同的PoD下 计算和内存资源总是倾向于部署在同一个ToR下，以获得更低的延迟与更少的页抖动    \rimage-20211222201043429\r\n无服务数据库 无服务数据库是云原生数据库的高弹性变种，主要目的是为了实现资源的按需分配\n 自动扩缩 auto-scaling  现存的无服务数据库的扩缩容因为是基于共享存储的架构，所以扩缩容受到限制。由于内存和CPU资源总是深度绑定在一个资源单位上，扩缩容也只能按照资源单位作为调动粒度。所以CPU和内存资源总是不能得到充分利用。 分析性数据库对内存的要求比较高，只需要少量的CPU资源来定期同步更新数据 事务性数据库少量的内存就可以保证缓存命中率，但需要更多的CPU资源来应对访问的高峰时刻   自动暂停 auto-pause  现存的无服务数据库的自动暂停也是受限的，CPU和内存资源必须被同时释放 在分散式架构下，CPU和内存不再共享命运。业务低峰期，内存可以不必释放，避免了重新加载。   扩容透明性 scaling transparency  透明性即在扩缩容的时候需要保证客户的场景不能中断或者性能出现严重影响 分散式架构下，中间临时状态如脏页、事务状态如版本信息timestamp、逻辑锁、query中间结果都可以保存在共享内存层，给实现扩缩容的透明性提供了更好的条件。 PolarDB Serverless 目前将脏页存在共享内存里，其他的临时状态期待后续的工作。    设计 PolarDB Serverless 基于PolarDB开发的分散式架构的云原生数据库。\n 组成：多个代理节点，一个RW节点，多个RO节点 使用PolarFS来做共享存储 和PolarDB的最大不同在于使用了远程内存池（共享内存）  使用共享内存\n 好处  RW和RO共用数据页，省去了每个节点自己保存副本，提高了内存的使用效率   坏处（performance penalty）  远程内存的访问速度远远低于本地内存；解决方案：分层内存系统和预取技术 私有数据放在公共资源上，需要有跨节点的互斥保护；解决方案：广泛使用单边的RDMA谓词和乐观协议来避免使用全局锁（global latch） 页的传输和网络带来了负担。解决方案：先将redo log写到存储层，再异步地通过日志将页物质化    分散化内存 远程内存访问接口  page_register: 页的引用计数增一 page_unregister: 页的引用计数减一 page_read: 使用单边RDMA谓词将页从远程内存读取到本地 page_write: 使用单边RDMA谓词将页从本地写到远程内存 page_invalidation: 使所有RO节点的本地的内存副本失效  远程内存管理 内存的分配单元是一个slab，一个slab的大小是1GB\n几种数据结构如下：\n Page Array（PA）  每一个slab由页数组组成，页数组是物理地址连续的由16KB的页组成的数组。 PA的地址会注册到RDMA的网卡上，所以可以被RDMA远程访问 负责提供slab访问的节点也叫slab node，第一个slab node 也叫home node   Page Address Table（PAT）  一个哈希表，存储每一页的位置（slab id 与物理地址）   Page Invalidation Bitmap (PIB)  一个位图，对应PAT的每一项记录invalidation bit，0表示内存中的是最新版本，1表示不是最新版本   Page Reference Directory(PRD)  一个map，对应于每个PAT项，记录引用了这个页的节点   Page Latch Table(PLT)  对于PAT中的每一项，管理其页锁（page latch）。 是一个全局的物理锁，用于多个数据库节点之间进行保护与同步读写 尤其用于保护B+树的结构一致性    page分配过程：\n 数据库向home node 发送page register请求 如果不存在，则遍历slab找到有空闲的slab，如果都没有空闲则使用LRU算法淘汰掉一些page 写入后，将page的为位置信息写入到PAT，返回page的远程地址和page latch  扩缩容：\n 扩容：home node 请求DBaaS分配新的slab，扩展buffer pool，PAT，PIB和PRD 缩容：page通过LRU进行淘汰，无用的slab将被回收  本地缓存  以page为单位将远程内存缓存到本地 如果page不在远程内存上，进程会从Polar FS读取内容到本地缓存，然后再写回到远程内存。（存储和内存不发生直接接触） 不是所有的page都要写入远程内存，例如全表扫描，这些page不太会再次访问 本地发生miss，进程要等待读取远程内存（可以利用预取技术） 本地的缓存写满后使用LRU算法进行淘汰。如果page没有修改过可以直接释放。如果page修改过，那就写回后再释放。引用计数减一。  缓存一致性  RO节点不能直接访问RW节点的本地缓存，只能通过获取最新的redo log来在本地物质化page来获取最新的数据。 如果RW节点将修改过的数据写回远程内存后，RO节点自然是不需要读取redo log，可是系统如果每次修改都要立刻写回，网络开销会很大。所以RW节点不会立刻写回，而是使用了页失效的方法。  \rimage-20211225120332727\r\n 具体过程如下：  RW修改page后，调用page_invalidation 发送请求到home node PIB中对应页项设置为1 查询PRD，查看page在哪些RO节点上存在 向所有的存在这个page的RO发送请求，将PIB设置为1 设置PIB过期是一个同步阻塞操作 只有全部的RO节点设置成功才返回成功 如果有个RO节点超时，那么就把他踢出集群来保证该操作成功   在写回到Polar FS（远程存储）的时候，同样会使用page_invalid来保证远程内存中不会存在比远程存储中更老版本的数据。  B+树结构一致性   物理一致性\n问题是：多线程访问B+树的Index的时候如何做到并发控制\n解决方案：\n  只有RW节点可以修改page，所以不需要管理多节点的写冲突。但是SMO（结构修改操作）会同时修改多个page，其他节点在遍历B+树的时候，不同的RO节点可能看到不一致的物理B+树结构。\n 我们使用全局页锁来解决这个问题，使用共享锁（S）和排他锁（X）。 区别于本地页锁，全局页锁用于保证多节点下的B+树索引结构一致性。使用crabbhing/lock coupling算法实现 所有参与SMO的节点会加上X锁，直到SMO结束。RO节点读取的时候要检查PLT，查看是否有X锁，并且向被读的页上加S锁。    对于RW节点要进行的insert和delete操作，我们采取两阶段做法\n 采用乐观并发控制，假设没有SMO操作，那就只需要本地的锁来作单节点并发控制。如果确实不需要进行SMO，那就顺利插入或者删除。 如果发现B+树的叶子节点相对空或者相对满，即很有可能要发生SMO操作，就启用悲观策略，这时候会对所有可能参与SMO的page加上X锁，直到SMO结束释放锁。这样锁的排序可以保证RO节点只能看到SMO之前或者之后的树结构，而不会是SMO的中间状态。      逻辑一致性\n 相同的数据可能会有多个事务进行并发处理，如何保证满足不同的快照隔离级别。    快照隔离 PolarDB Serverless 提供基于MVCC的快照隔离。事务的实现机制，是由快照的时间戳来控制事务能看到数据的版本信息。RW节点会维护一个中心化的的时间戳叫CTS，来为所有数据库节点分配全局单调递增的时间戳。\n一次读写事务需要获取两次时间戳（cts_read和cts_commit）；提交事务的时候所有记录和undo log中的记录都需要额外维护一个列来保存cts_commit;一个读写事务内的read总会返回一个cts_commit比cts_read要小的记录;每个记录都会有一个事务id字段来记录修改该记录的事务。\n一个只读事务则只需要在事务开始的时候获取cts_read时间戳即可。\n但是对于一些比较heavy的事务，无法迅速对所有记录更新cts_commit，因为这会在提交事务的时候带来大量的随机写。因此这个cts_commit的更新是异步执行的。这就导致了在并发事务处理的时候，无法得知该记录的cts_commit是否已经被写或者是否要被写，即无法得知先前的事务是否已经完成或者该记录是否与先前事务有关。\n解决方案：通过查询RW上的CTS Log数据结构，其是一个环形数组：记录着最近若干个的读写事务的提交时间戳(cts_commit)。如果先前事务没有完成，这个数组上的commit timestamp就会为null，每当一个节点读取到一个cts_commit为空的记录，就可以去查询这个全局的环形数组来得知这个记录对应的事务是否已经提交了。\n同样要去全局查这个时间戳要对应一次network request，本系统还是采用RDMA 来加速环形数组的访问获取时间戳的过程，RDMA CAS技术能够原子递增获取时间戳，并且这个数组的地址也会被注册到RDMA 的网卡上。和用RPC相比，直接走网卡不需要占用RW节点的CPU资源。\nPage Materialization Offloading 传统的DB会周期性的将脏页写入到持久性的存储中。Aurora提出了日志即数据库的概念，通过使用redo log来物质化页数据来获取最新版本的数据。Socrates在此基础上，则做到了将log与数据分离存储。\nPolarrDB Serverless和Socrates类似，将logs和pages分开存储在不同的chunks中。\n redo logs先存储在logs chunks中 异步发送到page chunks 为了PolarFS组件的重用和最小化更改，logs仅仅送到leader node。 然后leader node 重做并使用ParallelRaft保证副本的一致性  自动扩缩 在版本的升级和重启过程中，用户对Serverless服务是无感知的，断开连接，事务中断，请求超时是不允许的。\n所以在本系统中，当发生版本升级和跨节点迁移的时候，代理节点负责保持客户端连接，发送请求后会等待旧的RW节点处理掉正在进行的事务。之后把就节点的脏页flush到共享的内存池中，再关闭就RW节点。新的RW节点连接内存池，预热缓存，重做undo log来构建事务的列表。之后代理节点将连接还给新的RW节点。\n性能优化 使用分散式架构会带来性能的损失，所以要使用一些性能优化手段来进行优化。\n乐观锁 使用乐观锁可以尽可能避免并发操作对全局锁的获取，进而提高并行效率。\nRW节点会维护一个SMO counter，每次发生SMO的时候counter++；并且所有被修改的Page也会维护这个更新后的counter（SMO RW）\n每次query执行的时候去拿这个SMO counter（SMO query），一旦RO上的query发现某个Page的SMO counter比SMO query还要大，说明在query执行过程中发生了SMO。这个时候就要回滚到悲观并发控制，即获取全局PL来锁住整个B+ Tree的SMO更新。\n预取 在PolarDB Serverless中，我们提出了批处理密钥预处理(BKP)。BKP从分解的内存和存储中预取包含有趣的元组的页面，以隐藏远程I/O延迟。BKP的接口接受一组要预取的密钥。当调用该接口时，引擎将启动一个后台预取任务，从目标索引中检索所需的密钥，并在必要时从远程内存/存储中获取相应的数据页。BKP还可以优化分析工作负载。\n容错与恢复策略 数据库节点恢复 本系统采用的是ARIES的恢复算法（Algorithm for Recovery and Isolation Exploiting Semantics. ）\n RO节点的恢复：由于页数据再远程内存上，所以可以轻松地使用新的RO节点代替旧的RO节点 RW节点的恢复  无预期的节点故障  RW节点挂掉之后，集群的manager（CM）会通过心跳信号探测到，然后RO节点就可以晋升为RW节点。   有预期的节点故障  例如版本升级，前文已经讲过，不再赘述。      内存结点恢复 内存节点的数据缓存Page，在把dirty page写到内存节点前，对应的redo log已经flush到存储层了，因此内存节点重启可以用PolarFS上的redolog来进行恢复数据。\nhome node上因为包含重要的metadata如PAT，PIB，PRD和PLT；这些数据会同步备份在从副本；home node负责检测slab node上的故障，然后home node根据PAT上的信息来重建重启的slab node即可。\n集群恢复 在极少数情况下，当主节点的所有副本都不可用时，需要通过集群恢复来恢复服务。所有数据库节点和内存节点将从清除状态重新启动，所有内存状态将从存储重新启动。初始化后（连接到远程内存和存储器等），RW节点执行之前所述的并行REDO恢复，然后扫描撤销头以查找所有未完成的事务。之后，RW节点将启动服务，并在后台回滚未提交的事务。在集群恢复过程中，缓存在远程内存中的页面将被清除，因此它将忍受冷缓存问题。\n","date":"2021-12-22T14:17:12+08:00","image":"https://2021.sigmod.org/images/2021sigmod-logo1.jpg","permalink":"https://tweakzx.github.io/p/polardb-serverless%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E6%8A%A5%E5%91%8A/","title":"PolarDB Serverless论文阅读报告"},{"content":"1 HPL（High Performance Linpack) 假设要使用HPL程序在4个进程上解一个4096 * 4096的方程组（4096 * 4096的矩阵加一列方程组的右端项b），按照讲义第14页所示的block-cyclic方式对数据进行分配，NB=512。4个进程按1 * 4和4 * 1两种方式排布。那么，在HPL的回代部分（讲义48到55页），X的各个元素分别是由哪些进程算出的？例如，X[0..512]由进程(3, 0)求出。写出两种排布方式下X的各部分分别由哪些进程计算得到。（5分）\n 1 * 4 排布  \rimage-20211214170301242\r\n   X 进程     X[0..511] (0,0)   X[512..1023] (0,1)   X[1024..1535] (0,2)   X[1536..2047] (0,3)   X[2048..2559] (0,0)   X[2560..3071] (0,1)   X[3072..3583] (0,2)   X[3584..4095] (0,3)     4 * 1 排布  \rimage-20211214170325158\r\n   X 进程     X[0..511] (0,0)   X[512..1023] (0,1)   X[1024..1535] (0,2)   X[1536..2047] (0,3)   X[2048..2559] (0,0)   X[2560..3071] (0,1)   X[3072..3583] (0,2)   X[3584..4095] (0,3)    ","date":"2021-12-14T13:55:35+08:00","image":"https://gimg2.baidu.com/image_search/src=http%3A%2F%2Fpmob0455c.pic27.websiteonline.cn%2Fupload%2Felinpack3000-1200_dps0.jpg\u0026refer=http%3A%2F%2Fpmob0455c.pic27.websiteonline.cn\u0026app=2002\u0026size=f9999,10000\u0026q=a80\u0026n=0\u0026g=0n\u0026fmt=jpeg?sec=1642054231\u0026t=55c0893a251868314596e23dae76a843","permalink":"https://tweakzx.github.io/p/%E5%B9%B6%E8%A1%8C%E4%BD%9C%E4%B8%9A-3/","title":"并行作业 3"},{"content":"1 加速向量加法 #include \u0026lt;stdio.h\u0026gt;#include \u0026lt;assert.h\u0026gt; inline cudaError_t checkCuda(cudaError_t result) { if (result != cudaSuccess) { fprintf(stderr, \u0026#34;CUDA Runtime Error: %s\\n\u0026#34;, cudaGetErrorString(result)); assert(result == cudaSuccess); } return result; } void initWith(float num, float *a, int N) { for(int i = 0; i \u0026lt; N; ++i) { a[i] = num; } } __global__ void addVectorsInto(float *result, float *a, float *b, int N) { int initIndex = threadIdx.x + blockIdx.x * blockDim.x; int gridStride = gridDim.x * blockDim.x; for(int i = initIndex;i\u0026lt;N;i+=gridStride){ result[i] = a[i] + b[i]; } } void checkElementsAre(float target, float *array, int N) { for(int i = 0; i \u0026lt; N; i++) { if(array[i] != target) { printf(\u0026#34;FAIL: array[%d] - %0.0f does not equal %0.0f\\n\u0026#34;, i, array[i], target); exit(1); } } printf(\u0026#34;SUCCESS! All values added correctly.\\n\u0026#34;); } int main() { const int N = 2\u0026lt;\u0026lt;20; size_t size = N * sizeof(float); float *a; float *b; float *c; cudaMallocManaged(\u0026amp;a, size); cudaMallocManaged(\u0026amp;b, size); cudaMallocManaged(\u0026amp;c, size); initWith(3, a, N); initWith(4, b, N); initWith(0, c, N); size_t threads_per_block = 1024; size_t number_of_blocks = (N+threads_per_block-1)/threads_per_block; addVectorsInto\u0026lt;\u0026lt;\u0026lt;32,1024\u0026gt;\u0026gt;\u0026gt;(c, a, b, N); //addVectorsInto\u0026lt;\u0026lt;\u0026lt;number_of_blocks,threads_per_block\u0026gt;\u0026gt;\u0026gt;(c, a, b, N);  checkCuda(cudaGetLastError()); checkCuda(cudaDeviceSynchronize()); checkElementsAre(7, c, N); cudaFree(a); cudaFree(b); cudaFree(c); } 2 加速SAXPY #include \u0026lt;stdio.h\u0026gt;#include \u0026lt;assert.h\u0026gt;#define N 2048 * 2048 // Number of elements in each vector  /* * Optimize this already-accelerated codebase. Work iteratively, * and use nsys to support your work. * * Aim to profile `saxpy` (without modifying `N`) running under * 20us. * * Some bugs have been placed in this codebase for your edification. */ inline cudaError_t checkCuda(cudaError_t result) { if (result != cudaSuccess) { fprintf(stderr, \u0026#34;CUDA Runtime Error: %s\\n\u0026#34;, cudaGetErrorString(result)); assert(result == cudaSuccess); } return result; } __global__ void saxpy(float * a, float * b, float * c) { int tid = blockIdx.x * blockDim.x + threadIdx.x; int stride = gridDim.x * blockDim.x; for(int i = tid; i\u0026lt;N; i+=stride){ c[tid] = 2 * a[tid] + b[tid]; } } int main() { int deviceId; int numberOfSMs; cudaGetDevice(\u0026amp;deviceId); cudaDeviceGetAttribute(\u0026amp;numberOfSMs, cudaDevAttrMultiProcessorCount, deviceId); float *a, *b, *c; int size = N * sizeof (float); // The total number of bytes per vector  cudaMallocManaged(\u0026amp;a, size); cudaMallocManaged(\u0026amp;b, size); cudaMallocManaged(\u0026amp;c, size); // Initialize memory  for( int i = 0; i \u0026lt; N; ++i ) { a[i] = 2.0; b[i] = 1.0; c[i] = 0.0; } cudaMemPrefetchAsync(a, size, deviceId); cudaMemPrefetchAsync(b, size, deviceId); cudaMemPrefetchAsync(c, size, deviceId); int threads_per_block = 256; int number_of_blocks = numberOfSMs * 32 ; saxpy \u0026lt;\u0026lt;\u0026lt; number_of_blocks, threads_per_block \u0026gt;\u0026gt;\u0026gt; ( a, b, c ); checkCuda(cudaGetLastError()); checkCuda(cudaDeviceSynchronize()); // Print out the first and last 5 values of c for a quality check  for( int i = 0; i \u0026lt; 5; ++i ) printf(\u0026#34;c[%d] = %f, \u0026#34;, i, c[i]); printf (\u0026#34;\\n\u0026#34;); for( int i = N-5; i \u0026lt; N; ++i ) printf(\u0026#34;c[%d] = %f, \u0026#34;, i, c[i]); printf (\u0026#34;\\n\u0026#34;); cudaFree( a ); cudaFree( b ); cudaFree( c ); } 3 N-body #include \u0026lt;math.h\u0026gt;#include \u0026lt;stdio.h\u0026gt;#include \u0026lt;stdlib.h\u0026gt;#include \u0026#34;timer.h\u0026#34;#include \u0026#34;files.h\u0026#34; #define SOFTENING 1e-9f  #include \u0026lt;assert.h\u0026gt;inline cudaError_t checkCuda(cudaError_t result) { if (result != cudaSuccess) { fprintf(stderr, \u0026#34;CUDA Runtime Error: %s\\n\u0026#34;, cudaGetErrorString(result)); assert(result == cudaSuccess); } return result; } /* * Each body contains x, y, and z coordinate positions, * as well as velocities in the x, y, and z directions. */ typedef struct { float x, y, z, vx, vy, vz; } Body; /* * Calculate the gravitational impact of all bodies in the system * on all others. */ __global__ void bodyForce(Body *p, float dt, int n) { int index = blockIdx.x * blockDim.x + threadIdx.x; int stride = gridDim.x * blockDim.x; for (int i = index; i \u0026lt; n; i+=stride) { float Fx = 0.0f; float Fy = 0.0f; float Fz = 0.0f; for (int j = 0; j \u0026lt; n; j++) { float dx = p[j].x - p[i].x; float dy = p[j].y - p[i].y; float dz = p[j].z - p[i].z; float distSqr = dx*dx + dy*dy + dz*dz + SOFTENING; float invDist = rsqrtf(distSqr); float invDist3 = invDist * invDist * invDist; Fx += dx * invDist3; Fy += dy * invDist3; Fz += dz * invDist3; } p[i].vx += dt*Fx; p[i].vy += dt*Fy; p[i].vz += dt*Fz; } } int main(const int argc, const char** argv) { // The assessment will test against both 2\u0026lt;11 and 2\u0026lt;15.  // Feel free to pass the command line argument 15 when you gernate ./nbody report files  int nBodies = 2\u0026lt;\u0026lt;11; if (argc \u0026gt; 1) nBodies = 2\u0026lt;\u0026lt;atoi(argv[1]); // The assessment will pass hidden initialized values to check for correctness.  // You should not make changes to these files, or else the assessment will not work.  const char * initialized_values; const char * solution_values; if (nBodies == 2\u0026lt;\u0026lt;11) { initialized_values = \u0026#34;files/initialized_4096\u0026#34;; solution_values = \u0026#34;files/solution_4096\u0026#34;; } else { // nBodies == 2\u0026lt;\u0026lt;15  initialized_values = \u0026#34;files/initialized_65536\u0026#34;; solution_values = \u0026#34;files/solution_65536\u0026#34;; } if (argc \u0026gt; 2) initialized_values = argv[2]; if (argc \u0026gt; 3) solution_values = argv[3]; const float dt = 0.01f; // Time step  const int nIters = 10; // Simulation iterations  int bytes = nBodies * sizeof(Body); float *buf; cudaMallocManaged(\u0026amp;buf, bytes); Body *p = (Body*)buf; read_values_from_file(initialized_values, buf, bytes); double totalTime = 0.0; /* * This simulation will run for 10 cycles of time, calculating gravitational * interaction amongst bodies, and adjusting their positions to reflect. */ int deviceId; int numberOfSMs; cudaGetDevice(\u0026amp;deviceId); cudaDeviceGetAttribute(\u0026amp;numberOfSMs, cudaDevAttrMultiProcessorCount, deviceId); int threads_per_block = 128; int number_of_blocks = numberOfSMs * 25 ; for (int iter = 0; iter \u0026lt; nIters; iter++) { StartTimer(); /* * You will likely wish to refactor the work being done in `bodyForce`, * and potentially the work to integrate the positions. */ bodyForce\u0026lt;\u0026lt;\u0026lt;threads_per_block,number_of_blocks\u0026gt;\u0026gt;\u0026gt;(p, dt, nBodies); // compute interbody forces  checkCuda(cudaGetLastError()); checkCuda(cudaDeviceSynchronize()); /* * This position integration cannot occur until this round of `bodyForce` has completed. * Also, the next round of `bodyForce` cannot begin until the integration is complete. */ for (int i = 0 ; i \u0026lt; nBodies; i++) { // integrate position  p[i].x += p[i].vx*dt; p[i].y += p[i].vy*dt; p[i].z += p[i].vz*dt; } const double tElapsed = GetTimer() / 1000.0; totalTime += tElapsed; } double avgTime = totalTime / (double)(nIters); float billionsOfOpsPerSecond = 1e-9 * nBodies * nBodies / avgTime; write_values_to_file(solution_values, buf, bytes); // You will likely enjoy watching this value grow as you accelerate the application,  // but beware that a failure to correctly synchronize the device might result in  // unrealistically high values.  printf(\u0026#34;%0.3f Billion Interactions / second\u0026#34;, billionsOfOpsPerSecond); cudaFree(buf); } 4 证书 \rimage\r\n","date":"2021-12-13T19:03:20+08:00","image":"https://cdn.jsdelivr.net/gh/Tweakzx/ImageHost@main/img/image-20211215144717123.png","permalink":"https://tweakzx.github.io/p/cuda%E5%8A%A0%E9%80%9F%E8%AF%BE%E7%A8%8B%E9%A2%98%E7%9B%AE/","title":"CUDA加速课程题目"},{"content":"1 矩阵向量乘法（6分） 矩阵向量乘法(gemv)如何用OpenMP或pthread对其并行化(OpenMP和pthread任选一种即可)？假设矩阵按行存储（每一行数据是连续的），处理器有32个核。如果矩阵是按列存储呢？具体实现如何修改？\n可用语言详细描述或写出伪代码\n  按行存储\nvoid *worker1(int row, int N, int** A, int* vec, int* result){ for(int i = row; i\u0026lt;N; i += 32){ result[i] = innerProduct(A[i],Vec); } } int main(){ ... for(int i=0;i\u0026lt;32;i++){ data_array[i].row = i; pthread_create(\u0026amp;threads[i], NULL, worker1, (void *)\u0026amp;data_array[i]) } ... }   按列存储\nvoid *worker2(int column, int N, int M, int** A, int* vec, int* result){ for(int j = column; j\u0026lt;M; j += 32){ for(int i = 0; i\u0026lt;N; i++){ result[i] += A[j][i]*Vec[j]; } } } int main(){ ... for(int i=0;i\u0026lt;32;i++){ data_array[i].column = i; pthread_create(\u0026amp;threads[i], NULL, worker1, (void *)\u0026amp;data_array[i]) } ... }   2 程序分析（4分） 以下程序运行时会出现什么现象？可以如何改写来避免此现象发生？\nint selected_thread; sem_t start1, start2, stop1, stop2; void* worker1() { sem_wait(\u0026amp;start1); sem_post(\u0026amp;stop1); } void *worker2(){ sem_wait(\u0026amp;start2); sem_post(\u0026amp;stop2); } int main(int argc, char *argv[]) { selected_thread = 2; sem_init(\u0026amp;start1); sem_init(\u0026amp;start2); sem_init(\u0026amp;stop1); sem_init(\u0026amp;stop2); pthread_create(worker1); pthread_create(worker2); sem_post(\u0026amp;start1); sem_wait(\u0026amp;stop1); sem_wait(\u0026amp;stop2); return 0; } 答： worker2会一直等待，程序无法结束。所以在主函数里加上sem_post(\u0026amp;start2)。\n","date":"2021-12-11T18:01:26+08:00","image":"https://pic1.zhimg.com/v2-f9d2f5486443cc045996753d59f80a7e_1440w.jpg?source=172ae18b","permalink":"https://tweakzx.github.io/p/%E5%B9%B6%E8%A1%8C%E4%BD%9C%E4%B8%9A-2/","title":"并行作业 2"},{"content":"1矩阵向量乘法（4分） 讲义55页所示结果Y，如果要作为下一次矩阵向量乘法的输入X，切分到不同的列进程，并且复制到每一行进程，应如何操作？可写出伪代码，或用语言描述。\n即图(a)中的Y，变成下图(b)中的X。假设每行有P个进程，每列也是P个进程，一共P*P个进程。\n\rimage-20211210120943046\r\n答：进程$P_{ij}$和所控制的矩阵进行矩阵向量乘之后，将结果存入进程$P_{ji}$。\n2 代码填空（3分） 在测量程序性能时，我们经常要记录整个程序或程序中某一部分的运行时间。在MPI程序中，由于每个进程的运行时间不同，一般需要取各个进程运行时间的最大值，然后由0号进程保存和打印（其他进程不需要保存）。以下程序完成了这个功能，请在横线处填上函数调用语句。\nint main(int argc, char * argv) { double total_time; double time0, time1; int procs, rank; MPI_init(argc, argv); MPI_Comm_size(MPI_COMM_WORLD, \u0026amp;procs); MPI_Comm_rank(MPI_COMM_WORLD, \u0026amp;rank); time0 = MPI_Wtime(); //do some computation \ttime1 = MPI_Wtime() – time0; _______________________________________________________________ if(rank == 0) { Printf(“Total execution time is %f seconds\\n”, total_time); } } 答：\nMPI_Reduce(\u0026amp;time1,\u0026amp;total_time,1,MPI_DOUBLE,MPI_MAX,0,MPI_COMM_WORLD) 3 以下程序相当于哪个MPI聚合操作？（3分） #define N 16384 double *send_buff, *recv_buff; MPI_Status status; int i, nprocs, myid, count=N/num_procs; send_buff = (double*)malloc(N*sizeof(double)); recv_buff = (double*)malloc(N*sizeof(double)); MPI_Comm_size(MPI_COMM_WORLD, \u0026amp;nprocs); MPI_Comm_rank(MPI_COMM_WORLD, \u0026amp;myid); //此处省略send_buff中数据的初始化 memcpy((void*)(recv_buff + myid * count), (void*)(send_buff + myid * count), count*sizeof(double)); for(int i = 0; i \u0026lt; nprocs;i++) { if(i!=myid) { MPI_Sendrecv(send_buff+i*count, count, MPI_DOUBLE, i, 400, recv_buff+i*count, count, MPI_DOUBLE, i, 400, MPI_COMM_WORLD, \u0026amp;status); } } 答：MPI_Alltoall()\n","date":"2021-12-10T11:28:33+08:00","image":"https://img2.baidu.com/it/u=2900542081,1673808678\u0026fm=26\u0026fmt=auto","permalink":"https://tweakzx.github.io/p/%E5%B9%B6%E8%A1%8C%E4%BD%9C%E4%B8%9A-1/","title":"并行作业 1"},{"content":"1 逻辑时钟与一致割集 下图中，直线上小黑点给出了时钟计数，请分别用Lamport 逻辑时钟和向量时钟给图上的事件设置时间戳，并给出一致割集和非一致割集的例子。\n\r事件时钟计数\r\n答：\n  设置时间戳\n  Lamport逻辑时钟\n\rLamport逻辑时钟\r\n  向量时钟\n\r向量时钟\r\n    割集的例子\n  一致割集\n\r一致割集\r\n  非一致割集\n\r非一致割集\r\n包含$e_1^2$这个接收事件但是不包含$e_3^1$这个发送事件。\n    2 异步分布式系统的故障类型 考虑在异步分布式系统中使用的两个通信服务。在服务A中，消息可能丢失、被复制或延迟，校验和仅应用到消息头。在服务B中，消息可能丢失、延迟或发送地太快以致接收方无法处理它，但到达目的地的消息其内容一定正确。描述每个服务会有的故障类型。根据对有效性和完整性的影响将故障分类。服务B能被描述成一个可靠的通信服务吗？\n答：\n  服务A会有的故障类型\n 遗漏故障  消息丢失   拜占庭故障  checksum仅仅应用到消息的head，消息的body可能发生损坏 消息重复   因为这是异步分布式系统，所以不会有时序故障。  遗漏故障的消息丢失破坏了有效性。拜占庭故障的可能损坏的消息以及重复的消息破坏了完整性。\n  服务B会有的故障类型\n 遗漏故障  消息丢失 发送地太快以致接收方无法处理它，接收遗漏   因为这是异步分布式系统，所以不会有时序故障。  服务B满足完整性，但是服务B消息发生的遗漏故障，不满足有效性，所以不是可靠的通信服务。\n  3 Ricart and Agrawala 算法 请证明Ricart-Agrawala的互斥算法满足ME2和ME3。\n ME2:进入或退出临界区的请求最终都会成功\nME3:如果一个进入临界区的请求发生在先，那么进入临界区也按此顺序\nRicart-Agrawala算法：\n 一个进程申请资源时向所有其他进程发出带有时间戳的申请报文； 一个进程收到申请报文后，答复这个申请，当且仅当：1）若不在临界区并且自己未申请进入临界区,或者2)自己虽然发出了申请报文，但自己的报文的时间戳大于收到的申请报文。如果已经在临界区，或者自己的申请发送在前，则在出临界区之前将所有的申请挂起。 申请资源的进程仅在收到其它所有进程的回答报文后才进入临界区使用资源； 一个进程使用完资源后，它向所有挂起的申请发送回答报文。   证明：\n 证明满足ME2  一个进程$p_i$要进入临界区向其他进程发送请求，不想进入临界区的进程，或者已经发送了请求但是发送时间戳大于接收请求时间戳$T_i$的进程都会回复。所以进程$p_i$要等待逻辑时间戳$T_i$之前发送了请求的进程以及正在临界区的进程的答复。 在逻辑时间戳$T_i$之前发出请求的进程所等待进程的数量依次递减到1。等正在临界区的进程使用完资源并退出后，所有在等待的进程所需等待进程数量全都减1。此时有一个进程得到了全部的答复，进入临界区。 按照这个过程，只要前边的进程依次进入临界区并退出之后，进程$p_i$就可以成功进入临界区，毕竟没有进程可以插队，所需等待进程数量只能递减。 由于使用完资源后退出临界区不需要等待答复，所以可以成功退出。所以，满足ME2。   证明满足ME3  当进$p_i$给其他进程发送进入临界区的申请时 如果进程$p_j$也想进入临界区，发送的申请的时间戳小于收到的$T_i$，那么$p_j$不会发送答复给$p_i$,这样$p_i$就必须等待$p_j$进入并退出临界区之后才能得到答复，才有可能进入临界区。 如果进程$p_j$也想进入临界区，发送的申请的时间戳大于收到的$T_i$，那么他会回复$p_i$的申请，$p_i$无需等待$p_j$，且当$p_i$收到$p_j$的请求之后不会回复，$p_j$等待$p_i$。 所以，满足ME3    4 改进Ricart and Agrawala 算法 在Ricart-Agrawala的互斥算法中，原始假定系统的进程是不出故障的。请修改算法增加处理一个进程崩溃的情况。\n答：如果有进程崩溃，那么它永远不会回复，则发送请求的进程需要一直盲等。\n 所以每当接收到消息之后要做出答复，回复同意，当且仅当：1）若不在临界区并且自己未申请进入临界区,或者2)自己虽然发出了申请报文，但自己的报文的时间戳大于收到的申请报文。或者回复拒绝，当1）自己处在临界区，或者2）自己的临界区申请的逻辑时间戳小于收到的申请，把回复拒绝的进程缓存起来，等待回复。 如果超出timeout没有收到答复则认为机器故障，只需等待其余的机器全部回复同意 当一个进程退出临界区之后，要向所有回复拒绝的进程回复同意。  5改进基于环的互斥算法 改进基于环的互斥算法使得它能检测权标的丢失并重新生成权标。\n答：\n 一个进程发出申请之后，如果长时间没有拿到权标，则向下一个节点发送一个请求reqest确认权标是否还在。 一个进程收到了确认权标存在的请求request，如果权标在自己手里则向下一个节点发送一个exist，如果权标不在自己手里，则将requst传递给下一个节点 一个进程收到了一个exist消息则将它传递到下一个节点 如果发出申请的进程收到request请求，则认为权标丢失，重新生成权标。如果收到exist，则说明一切正常。  6 双向环结构的选举算法 基于环的选举算法是建立在单向环的假设之上的，为了获得更快的选举速度，现采用双向环结构，即每个节点可以同时向顺时针和逆时针两个方向发送选举消息，请列出新算法的高层描述，并用一个四节点的双向环来说明你的方法。\n答：\n 最初，所有进程标记为非参与者，任意一个进程发起选举，发起选举后，置自己为参与者（$elected_i = ⊥$)，向上下游发送一个选举消息，包含自己的标识符。 一个进程收到选举消息后，那么比较自己的标识符与收到消息中的标识符，  如果自己的标识符小于消息中的标识符，那么顺消息来的方向传递选举消息； 如果自己的标识符大于消息中的标识符  如果自己是非参与者，将消息中的标识符改为自己标识符，顺消息来的方向传递选举消息。 如果自己是参与者，则不转发消息。   如果自己的标识符等于消息中的标识符，那么说明自己的标识符最大，如果还未当选，则当选为协调者，向上游和下游发送一个当选消息，包含自己的标识符P   一个进程收到一个当选消息，如果自己是参与者，设置$elected_i = P$，置自己为非参与者，并且按照消息发送的方向传递给自己的邻居；如果自己已经知晓当选消息，则不转发。  Init elected != ⊥ for process i (i = 1,2,...N) in the process which start an election: function startElection(): electingMSG \u0026lt;- MSG(type = \u0026quot;electing\u0026quot;, value = Local.id) Local.elected = '⊥' send(msg = electingMSG ,direction = clockwise) send(msg = electingMSG , direction = counterclockwise) in process i: function handleMSG(MSG msg, Direction direction): if msg.type = \u0026quot;electing\u0026quot;: if Local.id \u0026lt; msg.id: send(msg,direction) Local.elected = '⊥' else if Local.id \u0026gt; msg.id: if Local.elected != '⊥': msg.value = Local.id send(msg, direction) Local.elected = '⊥' end else if(process i is not Coordinator) setCoordinator(process i) Local.elected = '⊥' electdeMSG \u0026lt;- MSG(type = \u0026quot;elected\u0026quot;, value = Local.id) send(msg = electedMSG, direction = clockwise) send(msg = electedMSG, direction = counterclockwise) end end end if msg.type = \u0026quot;elected\u0026quot; if Local.elected == '⊥': Local.elected = msg.value send(msg, direction) end end \rimage-20211209165145519\r\n图中:\t白色表示初始非参与者，黄色表示参与者，红色表示知道当选结果。蓝色是选举消息，绿色是当选消息。从13号开始发起选举，最终选出23为协调者。\n 网络带宽：找到最大标识符最多需要N个消息，确认最大标识符最多需要2N个消息，通知当选最多需要N+1个消息，则最多需要消息为 4N+1 回转时间：第一轮寻找花费最多(N/2)个消息，第二轮确认需要最多花费N个消息，第三轮通知最多需要花费(N/2)+1个消息，所以最多需要花费2N+1个消息的回转时间。  7 基于生成树的选举算法 节点之间按照生成树方式连接，仅有边相连的节点能通信，请基于此网络拓扑，设计一个选举算法，给出其伪码。当仅有一个进程发起选举，你的选举算法所需的消息量是多少？\n答：假定是有向生成树，每个节点有父节点和子节点，每个节点可以向子节点或者父节点发送消息。任何一个进程都可以发起选举。算法如下：\n  收到选举消息，将发送消息的标识符和自己的标识符作比较，更改消息中的信息为较大值；如果有子节点，则向子节点发送这个选举消息；如果是叶子节点，则父亲节点返回一个回复消息，包含当前的较大标识符。\n  等到收到所有子节点的回复消息，选出最大的标识符，返回给父亲节点\n  当根节点收到最大的 标识符，则向所有的子节点发送当选信息，直到叶节点。如果有子节点发现自己的标识符等于消息中的的标识符，则成为协调者。\n  我的选举算法所需的消息量选举有N-1个，回复有N-1个，当选有N-1个，所以总共有3N-3个。\nInit Local.elected != ⊥ for process i (i = 1,2,...N) Local.count =0 for process i (i = 1,2,...N) in the process p0 which start an election: function startElection(): electingMSG \u0026lt;- MSG(type = \u0026quot;electing\u0026quot;, value = Local.id) Local.elected = '⊥' for i in son(p0): send(electingMSG, dest = i) end in process p: function handleMSG(MSG msg): if msg.type = \u0026quot;electing\u0026quot;: Local.elected = '⊥' if !isEmpty(son(p): msg.value = max(Local.id,msg.value) for i in son(p): send(msg, dest = i) end else replyMSG = MSG(type = \u0026quot;reply\u0026quot;, value = max(Local.id,msg.value) send(relpyMSG, dest = father(p)) end if msg.type = \u0026quot;reply\u0026quot;: Local.count++; msg.value = max(Local.id, msg.value) if(Local.count == son(p).size()): if !isEmpty(father(p)): send(msg, dest = father(p)) else electedMSG = MSG(type = \u0026quot;elected\u0026quot;,value = msg.value) for i in son(p): send(electedMSG, dest = i) end Local.elected = msg.value if Local.ip == msg.value: setCoordinator(process = p) end end end end if msg.type = \u0026quot;elected\u0026quot;: if Local.ip == msg.value: setCoordinator(process = p) end if !isEmpty(son(p)): for i in son(p): send(msg, dest = i) end end 8 法定数共识复制 在服务器X、Y和Z上使用法定数共识进行复制，这些服务器都有数据项A和B的副本。A和B副本的初始值是100，并且在X、Y和Z上A和B的选票是1。同样对于A和B，R＝W＝2。一个客户读A的值然后将它写到B上。\n1）当客户执行这些操作时，出现了一个分区，将服务器X和Y与服务器Z分隔开了。描述当客户能访问服务器X和Y时，获得的法定数和发生的操作。\n2）描述当客户仅能访问服务器Z时，获得的法定数和发生的操作。\n3）分区修复了，然后另一个分区发生了，结果X和Z与Y分隔开了。描述当客户能访问服务器X和Z时，获得的法定数和发生的操作。\n答：\n1）在数据的v0版本时，A和B副本的初始值是100，出现了一个分区，将服务器X和Y与服务器Z分隔开。\n   X Y Z     A = 100（v0) A = 100（v0) A = 100（v0)   B = 100（v0) B = 100（v0) B = 100（v0)    ​\t客户可能从X或者Y上读取A，R = 1+1 =2，读取成功。\n​\t客户需要在X和Y上写B，W = 1+1 = 2， 写成功。\n2)客户只能访问服务器Z，R = 1，客户无法读取；W = 1，客户无法写。\n3)当分区被修复后，因为之前的分区导致X和Y的数据要比Z上的数据更新，例如\n   X Y Z     A = 200（v1) A = 200（v1) A = 100（v0)   B = 300（v1) B = 300（v1) B = 100（v0)    此时，另一个分区出现，X和Z与Y分隔开，当客户试图获取法定数的时候，发现Z的数据版本过时，于是Z根据X上的最新数据更新自己。之后客户获取读法定数，R = 1+1 =2，然后读成功。客户获取写法定数，W = 1+1 =2，写成功。\n9 串行等价的交错执行 一个服务器管理对象a1, a2, \u0026hellip; an ，它为客户提供下面两种操作：read (i)返回对象ai的值。write(i, Value)将对象ai设置为值Value。\n事务T和U定义如下：\nT: x = read(j); y = read (i); write(j, 44); write(i, 33)\nU: x = read(k); write(i, 55); y = read (j); write(k, 66)\n请给出事务T和U的3个串行化等价的交错执行。\n答：我们给每一步分别表上序号：\nT: ①x = read(j); ②y = read (i); ③write(j, 44); ④write(i, 33)\nU: ⑤x = read(k); ⑥write(i, 55); ⑦y = read (j); ⑧write(k, 66)\n如果按照先T后U的顺序依次执行一个事务的话，我们发现①和⑤，②和⑦，④和⑥有写后写依赖；③和⑦有写后读依赖，①和③，②和④，②和⑥，⑤和⑧有读后写依赖，所以，我们要保证这些依赖的逻辑顺序，串行化等价的交错执行如下：\n①⑤②③④⑥⑦⑧\n①③⑤②④⑦⑧⑥\n①⑤③②⑧⑦④⑥\n10 乐观并发控制 考虑将乐观并发控制应用于下列事务T和U的情况：\n​ T: x = read(i); write(j, 44);\n​ U: write(i, 55); write(j, 66);\n如果事务T和U同时处于活动状态，试描述以下几种情况的结果如何：\n 服务器首先处理T的提交请求，使用向后验证方式。 服务器首先处理U的提交请求，使用向后验证方式。 服务器首先处理T的提交请求，使用向前验证方式。 服务器首先处理U的提交请求，使用向前验证方式。  对于上面的每种情况，描述事务T和U的操作顺序，注意写操作在验证通过之后才真正起作用。\n答：\n  服务器首先处理T的提交请求，使用向后验证方式。\nT先开始所以T的验证阶段无事发生，U进入验证阶段之后，U没有读集，所以没有冲突，可以顺利提交。\n  服务器首先处理U的提交请求，使用向后验证方式。\nT进入验证阶段，发现T的读集{i}与U的写集{i, j}有冲突，T事务被放弃。\n  服务器首先处理T的提交请求，使用向前验证方式。\nU进入验证阶段，发现U的写集{i,j}与T的读集{i}有冲突，所以推迟验证，等T的读集执行完毕之后再提交U。\n  服务器首先处理U的提交请求，使用向前验证方式。\nT进入验证阶段，发现U无读集，所以可以通过验证。\n  ","date":"2021-12-07T14:21:24+08:00","image":"https://img2.baidu.com/it/u=1163044150,1040852846\u0026fm=26\u0026fmt=auto","permalink":"https://tweakzx.github.io/p/%E5%88%86%E5%B8%83%E5%BC%8F%E5%B7%A9%E5%9B%BA%E7%B1%BB%E4%BD%9C%E4%B8%9A/","title":"分布式巩固类作业"},{"content":" 时间：2021-12-2 下午5点半\n方式：阿里会议视频面试\n岗位：研究型实习生-智能存储\n 面试过程 这次面试主要是在聊项目，聊兴趣啥的。没有什么算法或者知识点的提问。\n 先做一下自我介绍。 问我觉得自己在学习上的最大优势是什么。 问我大三实习的主要工作，这一部分我还是忽略的带过了。 讲了自己的大二时的比赛。 问了可以实习的时间。 目前在学校里都学了什么课程。 面试官问我大四在做什么，我回答自己保研后在课题组里做结项的事情。面试官比较好奇我自己都做了什么，我回答东西都是别人做的，我就是提供一些辅助性的工作。 然后询问我课题组的主要研究是什么，我回答云计算，docker，k8s之类的。面试官问那为啥你做的东西和云计算一点关系都没有，又去做了算法NLP，我回答这是老师安排的。 问我对docker，k8s了解多少。我回答仅仅会简单的使用。 后来面试官解释NLP之类的工作一般是达摩院内边来做，意思可能是这边还是偏重于开发。 问我对这个部门的工作了解吗，一面有介绍吗？我回答和存储，预训练模型好像有关。 面试官说你要自己想好自己要做什么方向，兴趣是最好的老师啥的。（我也想啊） 面试官问我对NLP了解多少，我说仅仅毕业设计和这个有关，知道预训练和蒸馏。 他说感觉你对这些方面都有一点了解，但又都不深，不知道你将来要做什么。我回答自己目前还在探索，打算先开始做在去感受自己想要什么。 感觉聊到这里，其实已经无话可聊了。  下面是反问环节\n 我说自己可能问的问题比较大不好回答：如果我有机会得到这个offer，那我需要弥补的差距在什么地方？ 面试官从两个方面建议，一个就是如果计算想搞算法的话，blabla我忘了。如果想做开发的话，可以学习一下云原生，云计算之类的知识。 面试官分析了一下之后，我回答自己的理解与看法 ，主要说了人工智能是一种拿来应用的技术，做工程的过程中拿来使用，是工程的一部分。不是所有人都要去研究模型，我们能拿来即用即可，还是要去提升工程上的开发能力。  面试总结 我其实看不出来这次的结果好坏，面试官也确实提到了欢迎来去做一些尝试，可以先进来，实习的过程中摸索自己的兴趣，感受一下各个方向是什么样的，但更像是一些 说法正确的客套话。\n目前还在等结果。（希望结果是好的吧）\n","date":"2021-12-04T18:31:16+08:00","image":"https://img2.baidu.com/it/u=3334504742,937198599\u0026fm=26\u0026fmt=auto","permalink":"https://tweakzx.github.io/p/%E9%98%BF%E9%87%8C%E5%AE%9E%E4%B9%A0%E4%BA%8C%E9%9D%A2/","title":"阿里实习二面"},{"content":" 时间：2021-11-30 下午2点\n方式：阿里会议视频面试\n岗位：研究型实习生-智能存储\n 为什么会参加这次面试？ 因为想要亲身参与真实的科研活动或者一个真实企业内的做工程的过程，所以投递了这份简历，我也没有想到会给我安排面试。其实面试的时候我已经忘记自己投递的是哪个课题了，现在推测一下可能是大规模预训练模型的迁移啥的。\n因为面试的前一天参加了字节的面试，十分挫败，所以对面试可以说十分没有信心，加上收到的邮件里没有会议链接。无论面与不面，迟早要打电话告知，所以索性决定打电话推辞掉这个面试。打了电话，估计中午面试联系人可能在休息，所以过了一会才接到，面试联系人劝说我面试没有坏的影响，就当锻炼自己，只有好处没有坏处，不如一试。所以没有推脱，反正就一个小时，一个小时之后我的生活还会恢复原样。\n面试过程 面试的时候发现刚刚接电话的人应该就是面试官，面试官给我详细介绍了一下什么是研究型实习生以及它和其他的实习生的区别，以及对招聘的影响。然后就开始面试，先是自我介绍，还是介绍了本科，研究生的学校和专业，实习与比赛。问了我大概想做科研还是偏工程的方向，我回答工程，但后来想想应该回答我都行的其实。\n  面试了一道算法题：\n 将一个字符串按单词反转，但是对空间的开销有限制，最好是在原地址上直接修改，如果用栈，或者切割单词成数组之类的方式都是不符合空间开销要求的。\n 刚开始我想的是将单词先切出来，面试官发现我可能没有理解题目就又说了一下。\n我之后想说判断空格 然后做首尾交换，面试官提醒我单词的长度可能是不一致的，让我再想想。\n面试官说可以先说一下思路，再写代码。（说实话这点还挺赞的。）\n最后我想了想，说实话因为没有什么信心，我都想放弃算了。\n但偏偏还是想到了先把每个单词都先在局部反转，然后全局一起反转就不会产生大的空间开销。\n面试官说这个想法是对的，然后让我自己实现一下，就大概写了写代码。\n又问了我这个算法的时间复杂度是多少，我说是O(n)。\n  问平时怎么做测试，我回答用自己设计测试样例，然后print的方法和编辑器调试。\n他问我有么有用什么测试工具之类的，我说在课上学过UnitTest4，但实际上没用过。\n  知不知道多线程，pthread之类的。\n  之后聊了实习，实习时写的Json工具，日志接口开发。我都回答其实没有什么含金量。\n  然后是机器人大赛，路径规划算法用的是A* ,问我为什么用A* 而不是用机器人走迷宫的方式来操控机器人。和视觉算法的设计，以及OpenCV啥的。\n  最后聊了本科毕设，介绍了自己的毕设内容，问我觉得最有挑战的部分是啥。我回答是loss函数的设计，三段蒸馏，每段的不同的损失计算方法。\n  然后就是反问环节，我没问，确实不知道问啥。\n面试总结 大概就只记得这些了，好像忘记了很多其他的细节，但是面试完心情也比之前好了一些。\n阿里巴巴的这次面试给我最大的感受就是，面试官会确认自己的意思有没有准确传达给我，这个细节还挺令我感动的。面试官会把自己的问题或者很多要考虑的情况讲的很细致，确认我理解之后再让我思考并回答，这样其实对我这样不太熟悉面试的人十分友好的。\n面试的结果还不知道，但是无论好与坏，这次面试都给了我一些鼓舞，即便是结果不太好，我也不会气馁，不管怎么样都要继续努力。（希望结果是好的吧）\n后来接到了二面的电话，所以一面应该是过了。\n","date":"2021-12-01T21:49:57+08:00","image":"https://img2.baidu.com/it/u=3334504742,937198599\u0026fm=26\u0026fmt=auto","permalink":"https://tweakzx.github.io/p/%E9%98%BF%E9%87%8C%E7%A0%94%E7%A9%B6%E5%9E%8B%E5%AE%9E%E4%B9%A0%E7%94%9F%E9%9D%A2%E8%AF%95/","title":"阿里研究型实习生面试"},{"content":" 时间：2021-11-26 下午六点\n方式：飞书视频面试\n岗位：后端开发\n 为什么会面试蓝湖 心血来潮想要出去实习，在校友群内发了求助。24号中午，本科的同班同学涛神问我想不想试一试蓝湖，我想要一份实习来提升自己的代码水平，所以当然要抓住这次机会。\n所以中午抓紧时间写了一份简历交给了涛神帮忙内推。涛神问我要不要先准备一下，我说不了，早解决早轻松，可能是犯蠢了，也可能是太了解自己，我不是会好好规划复习的人，所以不如趁着热情直接上。\n面试的过程 面试官还是很温柔的，上来先让我做了一下自我介绍，我介绍了一下本科和硕士，以及一段实习经历，一段比赛经历。让说一下觉得最有有挑战性的工作？实习和比赛都很水，所以实话实说没啥亮点。\n算法题一道，写一下快排。当时代码没有跑起来，因为vscode好像更新了code runner的配置，所以没有跑起来，不过写的代码大概率全是bug，代码能力也是硬伤。\nclass Solution { public: int qsort(vector\u0026lt;int\u0026gt;\u0026amp; nums,int left,int right){ int l = left; int r = right; if(l\u0026gt;=r){ return l; } int randNum = rand()%(r-l+1)+l; int temp = nums[randNum]; nums[randNum] = nums[l]; nums[l] = temp; int pivot = nums[l]; while(l\u0026lt;r){ while(l\u0026lt;r\u0026amp;\u0026amp;nums[r]\u0026gt;pivot){ r--; } nums[l] = nums[r]; while(l\u0026lt;r\u0026amp;\u0026amp;nums[l]\u0026lt;=pivot){ l++; } nums[r] = nums[l]; } nums[l] = pivot; qsort(nums,left,l-1); qsort(nums,l+1,right); return l; } vector\u0026lt;int\u0026gt; sortArray(vector\u0026lt;int\u0026gt;\u0026amp; nums) { srand((unsigned)time(NULL)); qsort(nums,0,(int)nums.size()-1); return nums; } }; 然后问了一些基础问题：\n  Java和C++的区别有哪些\n  类的重写和重载\n  TCP通信的三次握手和四次挥手，为什么不能多一次或者少一次？\n  TCP长连接和短链接\n  TCP和UDP的区别\n  了解Cache吗？我答非所问，回答了操作系统的cache。\n  其实有可能是问http缓存\n  输入url地址浏览器的变化\n  问有么有用过数据库，对数据库了解多少，回答用过MySQL\n  为什么要用数据库？\n  简单介绍一下云计算是什么，为什么要用云计算\n  面试总结 面完就知道自己应该是凉了，果然12月1号收到了感谢信。其实还是老问题，自己的基础知识还是要在巩固一下可能要多看看面经，另外算法什么的还是要多加练习。\n后来涛神告诉我是HR觉得只有一个月多的实习时间太短了，不好安排。\n","date":"2021-12-01T20:56:54+08:00","image":"https://cdn.jsdelivr.net/gh/Tweakzx/ImageHost@main/img/image-20211201214555354.png","permalink":"https://tweakzx.github.io/p/%E8%93%9D%E6%B9%96%E9%9D%A2%E8%AF%95%E5%87%89%E7%BB%8F/","title":"蓝湖面试凉经"},{"content":" 时间：2021-11-29下午三点\n方式：飞书视频面试\n岗位：后端开发实习生-业务中台职位\n 为什么会投递字节实习 ​\t因为中科院的研究所大多不让实习，研二想去实习是一定不行的。但是研一在雁栖湖，课题组在海淀，我研一基本不参与科研，所以想要趁没人管的时候出去实习。因为将来大概率是做软开，所以想找一份后端开发的工作。在校友群里问了一下，有学长给了一个内推的机会，所以就有了这次一面。\n面试过程 ​\t面试官上来让我做了自我介绍之后就让我写代码做题。\n 题目一：链表1-\u0026gt;2-\u0026gt;3-\u0026gt;4-\u0026gt;5-\u0026gt;6 转变成 链表1-\u0026gt;6-\u0026gt;2-\u0026gt;5-\u0026gt;3-\u0026gt;4\n大概意思就是将链表平分成两部分，前一部分顺序不变，后一部分反转后插空插入前一部分链表。\n ​\t说实话，自己的代码能力确实有点差，原本打算使用c++来写后来改成了Java，因为我想起Java里有LinkedList这个数据结构。理由有点荒诞哈，其实是我没有意识到要自己定义节点来实现链表，所以在想要写指针的时候就卡住了，完全不知道怎么给LinkedList的链表写指针。然后就尬住了，面试官无奈说那就换一道吧。\n 题目二：判断一个二叉树是否是平衡树\n ​\t题目不是很难，但是自己太久不写代码有些生疏了，写出来的程序不知道为什么没有编译通过。说实话，面试官让我自己实现一个单例来测试程序，其中爆出的各种错误，无一不揭示了我完全没有什么开发经验的事实，例如内部类放错了位置，static的编译问题，还有一个空指针异常。无疑是再次尬死了。\n​\t之后面试官让我讲一讲自己的项目经历，主要问了一下大三在华为的实习。可惜自己虽然实习了，但实际的工作很少，含金量也不高，面试官兴趣不大。\n​\t之后就是问我有没有什么想问他的，我已经不想说话了，就没问。\n​\t草草结束。\n总结 首先还是把这两道题的代码写写吧 题目一 /** * @author lizhixuan * @version 1.0 * @date 2021/12/1 15:50 */ public class ReverseList2 { public static class ListNode { int val; ListNode next; ListNode() {} ListNode(int val) { this.val = val; } ListNode(int val, ListNode next) { this.val = val; this.next = next; } } public static ListNode createInstance(int n){ ListNode head = new ListNode(1); ListNode current = head; for (int i = 2; i \u0026lt;= n; i++) { current.next = new ListNode(i); current = current.next; } return head; } public static void printList(ListNode head){ ListNode current = head; while(current.next!=null){ System.out.print(current.val); System.out.print(\u0026#34;-\u0026gt;\u0026#34;); current = current.next; } System.out.println(current.val); } public static ListNode reverse(ListNode head){ ListNode pre = null; ListNode current = head; ListNode next; while(current!=null){ next = current.next; current.next = pre; pre = current; current = next; } return pre; } public static ListNode mergeList(ListNode l1,ListNode l2){ ListNode head = l1; ListNode l1Next; ListNode l2Next; while(l1!=null\u0026amp;\u0026amp;l2!=null){ l1Next = l1.next; l2Next = l2.next; l1.next = l2; l2.next = l1Next; l1 = l1Next; l2 = l2Next; } return head; } public static ListNode reverseHalf(ListNode head){ ListNode fast = head; ListNode slow = head; while(fast != null){ if(fast.next == null){ break; } if(fast.next.next == null){ break; } fast = fast.next.next; slow = slow.next; } ListNode half = reverse(slow.next); slow.next = null; return mergeList(head,half); } public static void main(String[] args) { ListNode head = createInstance(7); printList(head); head = reverseHalf(head); printList(head); } } 题目二 import java.util.LinkedList; import java.util.Queue; /** * @author lizhixuan * @version 1.0 * @date 2021/12/1 17:24 */ public class BalanceCheck { public static class TreeNode{ int val; TreeNode left; TreeNode right; TreeNode(int val){this.val = val;} } public static TreeNode listToTree(String src){ src = src.substring(1,src.length()-1); String[] strList = src.split(\u0026#34;,\u0026#34;); TreeNode root ; TreeNode result = null; Queue\u0026lt;TreeNode\u0026gt; queue = new LinkedList\u0026lt;\u0026gt;(); for (int i =0 ; i\u0026lt; strList.length ; i++){ if (i == 0){ root = new TreeNode(Integer.parseInt(strList[i])); result = root; queue.add(root); } if (!queue.isEmpty()){ root = queue.poll(); }else { break; } if ( i+1 \u0026lt; strList.length \u0026amp;\u0026amp; !strList[i+1].equals( \u0026#34;null\u0026#34;)){ root.left = new TreeNode(Integer.parseInt(strList[i +1])); queue.add(root.left); } if ( i + 2 \u0026lt; strList.length \u0026amp;\u0026amp; !strList[i+2].equals( \u0026#34;null\u0026#34;)){ root.right = new TreeNode(Integer.parseInt(strList[i +2])); queue.add(root.right); } i = i +1; } return result; } public static int getHeight(TreeNode root){ if(root==null){ return 0; } return Math.max(getHeight(root.left),getHeight(root.right))+1; } public static boolean isBalanced(TreeNode root){ if(root==null){ return true; } int leftHeight = getHeight(root.left); int rightHeight = getHeight(root.right); return Math.abs(leftHeight-rightHeight)\u0026lt;=1 \u0026amp;\u0026amp; isBalanced(root.left) \u0026amp;\u0026amp; isBalanced(root.right); } public static void main(String[] args) { String tree = \u0026#34;[3,9,20,null,null,15,7]\u0026#34;; TreeNode root = listToTree(tree); System.out.println(isBalanced(root)); } } 一些知识点   java内部类：\n 成员内部类中不能存在任何static的变量和方法 成员内部类是依附于外围类的，所以只有先创建了外围类才能够创建内部类    java的static关键字\n static变量也称作静态变量，静态变量被所有的对象所共享，在内存中只有一个副本，它当且仅当在类初次加载时会被初始化。 为什么说static块可以用来优化程序性能，是因为它的特性:只会在类加载的时候执行一次。 在C/C++中static是可以作用域局部变量的，但是在Java中切记：static是不允许用来修饰局部变量。    反思  自己还是缺乏代码经验，代码写不出来，面试官明显十分失望，失去耐心之后多次叹气捂脸，说实话压力还是挺大的，毕竟确实挺丢脸的。以后也要多写一点代码。 打算把自己的学习总结下来，于是也有了这篇博客，希望自己可以坚持写博客，说实话，面试完压力挺大，感觉自己就是一个无敌铁废物，写博客写出来感觉好一些了。  ","date":"2021-11-29T16:52:26+08:00","image":"https://cdn.jsdelivr.net/gh/Tweakzx/ImageHost@main/img/bytedance.jpg","permalink":"https://tweakzx.github.io/p/%E5%AD%97%E8%8A%82%E5%AE%9E%E4%B9%A0%E9%9D%A2%E8%AF%95%E5%87%89%E7%BB%8F/","title":"字节实习面试凉经"}]